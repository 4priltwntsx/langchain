{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635d8ebb",
   "metadata": {},
   "source": [
    "# Adaptive RAG\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì€ Adaptive RAG(Adaptive Retrieval-Augmented Generation)ì˜ êµ¬í˜„ì„ ë‹¤ë£¹ë‹ˆë‹¤. \n",
    "\n",
    "Adaptive RAGëŠ” ì¿¼ë¦¬ ë¶„ì„ê³¼ ëŠ¥ë™ì /ìê¸° ìˆ˜ì • RAGë¥¼ ê²°í•©í•˜ì—¬ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìƒì„±í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤. \n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ê²€ìƒ‰ê³¼ ìê¸° ìˆ˜ì • RAG ê°„ì˜ ë¼ìš°íŒ…ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ë¡œ ë‹¤ë£¨ëŠ” ë‚´ìš©**\n",
    "\n",
    "- **Create Index**: ì¸ë±ìŠ¤ ìƒì„± ë° ë¬¸ì„œ ë¡œë“œ\n",
    "- **LLMs**: LLMì„ ì‚¬ìš©í•œ ì¿¼ë¦¬ ë¼ìš°íŒ… ë° ë¬¸ì„œ í‰ê°€\n",
    "- **Web Search Tool**: ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„¤ì •\n",
    "- **Construct the Graph**: ê·¸ë˜í”„ ìƒíƒœ ë° íë¦„ ì •ì˜\n",
    "- **Compile Graph**: ê·¸ë˜í”„ ì»´íŒŒì¼ ë° ì›Œí¬í”Œë¡œìš° êµ¬ì¶•\n",
    "- **Use Graph**: ê·¸ë˜í”„ ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸\n",
    "\n",
    "----\n",
    "\n",
    "**Adaptive RAG**ëŠ” **RAG**ì˜ ì „ëµìœ¼ë¡œ, (1) [ì¿¼ë¦¬ ë¶„ì„](https://blog.langchain.dev/query-construction/)ê³¼ (2) [Self-Reflective RAG](https://blog.langchain.dev/agentic-rag-with-langgraph/)ì„ ê²°í•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "[ë…¼ë¬¸: Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://arxiv.org/abs/2403.14403) ì—ì„œëŠ” ì¿¼ë¦¬ ë¶„ì„ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ë¼ìš°íŒ…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `No Retrieval`\n",
    "- `Single-shot RAG`\n",
    "- `Iterative RAG`\n",
    "\n",
    "LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ êµ¬í˜„ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë¼ìš°íŒ…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì›¹ ê²€ìƒ‰**: ìµœì‹  ì´ë²¤íŠ¸ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì— ì‚¬ìš©\n",
    "- **ìê¸° ìˆ˜ì • RAG**: ì¸ë±ìŠ¤ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì— ì‚¬ìš©\n",
    "\n",
    "![adaptive-rag.png](./assets/langgraph-adaptive-rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7aba4",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb73bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25ec196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9065ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "CH13-LangGraph-Structures\n"
     ]
    }
   ],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"CH13-LangGraph-Structures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00c3f4",
   "metadata": {},
   "source": [
    "## ê¸°ë³¸ PDF ê¸°ë°˜ Retrieval Chain ìƒì„±\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” PDF ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ Retrieval Chain ì„ ìƒì„±í•©ë‹ˆë‹¤. ê°€ì¥ ë‹¨ìˆœí•œ êµ¬ì¡°ì˜ Retrieval Chain ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¨, LangGraph ì—ì„œëŠ” Retirever ì™€ Chain ì„ ë”°ë¡œ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ë˜ì•¼ ê° ë…¸ë“œë³„ë¡œ ì„¸ë¶€ ì²˜ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì°¸ê³ **\n",
    "\n",
    "- ì´ì „ íŠœí† ë¦¬ì–¼ì—ì„œ ë‹¤ë£¬ ë‚´ìš©ì´ë¯€ë¡œ, ìì„¸í•œ ì„¤ëª…ì€ ìƒëµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69cb77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf\"]).create_chain()\n",
    "\n",
    "# retriever ìƒì„±\n",
    "pdf_retriever = pdf.retriever\n",
    "\n",
    "# chain ìƒì„±\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fc536",
   "metadata": {},
   "source": [
    "## ì¿¼ë¦¬ ë¼ìš°íŒ…ê³¼ ë¬¸ì„œ í‰ê°€\n",
    "\n",
    "**LLMs** ë‹¨ê³„ì—ì„œëŠ” **ì¿¼ë¦¬ ë¼ìš°íŒ…**ê³¼ **ë¬¸ì„œ í‰ê°€**ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ **Adaptive RAG**ì˜ ì¤‘ìš”í•œ ë¶€ë¶„ìœ¼ë¡œ, íš¨ìœ¨ì ì¸ ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì— ê¸°ì—¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì¿¼ë¦¬ ë¼ìš°íŒ…**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì •ë³´ ì†ŒìŠ¤ë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì¿¼ë¦¬ì˜ ëª©ì ì— ë§ëŠ” ìµœì ì˜ ê²€ìƒ‰ ê²½ë¡œë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- **ë¬¸ì„œ í‰ê°€**: ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í’ˆì§ˆê³¼ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ì—¬ ìµœì¢… ê²°ê³¼ì˜ ì •í™•ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì´ ê³¼ì •ì€ **LLMs**ì˜ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë‹¨ê³„ëŠ” **Adaptive RAG**ì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ì§€ì›í•˜ë©°, ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ ì œê³µì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b78d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "# ìµœì‹  LLM ëª¨ë¸ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë°ì´í„° ì†ŒìŠ¤ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ë°ì´í„° ëª¨ë¸\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    # ë°ì´í„° ì†ŒìŠ¤ ì„ íƒì„ ìœ„í•œ ë¦¬í„°ëŸ´ íƒ€ì… í•„ë“œ\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM ì´ˆê¸°í™” ë° í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "## LLMì´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ë³´ê³  ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ê²°ì • -> ìì„¸í•˜ê²Œ ì‘ì„±\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "The vectorstore contains documents related to DEC 2023 AI Brief Report(SPRI) with Samsung Gause, Anthropic, etc.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
    "\n",
    "# Routing ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ êµ¬ì¡°í™”ëœ LLM ë¼ìš°í„°ë¥¼ ê²°í•©í•˜ì—¬ ì§ˆë¬¸ ë¼ìš°í„° ìƒì„±\n",
    "question_router = route_prompt | structured_llm_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e41f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteQuery(datasource='vectorstore')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RouteQuery(datasource=\"vectorstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4d831",
   "metadata": {},
   "source": [
    "ë‹¤ìŒì€ ì¿¼ë¦¬ ë¼ìš°íŒ… ê²°ê³¼ë¥¼ í…ŒìŠ¤íŠ¸ í•´ë³¸ ë’¤ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0874c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"AI Brief ì—ì„œ ì‚¼ì„±ì „ìê°€ ë§Œë“  ìƒì„±í˜• AI ì˜ ì´ë¦„ì€?\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d22b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='web_search'\n"
     ]
    }
   ],
   "source": [
    "# ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
    "print(question_router.invoke({\"question\": \"íŒêµì—ì„œ ê°€ì¥ ë§›ìˆëŠ” ë”¤ì„¬ì§‘ ì°¾ì•„ì¤˜\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc43b99",
   "metadata": {},
   "source": [
    "### ê²€ìƒ‰ í‰ê°€ê¸°(Retrieval Grader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1221d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„° ëª¨ë¸ ì •ì˜\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM ì´ˆê¸°í™” ë° í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ê²€ìƒ‰ê²°ê³¼ í‰ê°€ê¸° ìƒì„±\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927cac10",
   "metadata": {},
   "source": [
    "ìƒì„±í•œ `retrieval_grader` ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ê²°ê³¼ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa5e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì§ˆë¬¸ ì„¤ì •\n",
    "question = \"ì‚¼ì„±ì „ìê°€ ë§Œë“  ìƒì„±í˜• AI ì˜ ì´ë¦„ì€?\"\n",
    "\n",
    "# ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "docs = pdf_retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef397b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "# ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°\n",
    "retrieved_doc = docs[1].page_content\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ì¶œë ¥\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": retrieved_doc}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce41bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„í„°ë§ í•˜ëŠ” ì½”ë“œ ì˜ˆì‹œ\n",
    "filtered_docs = []\n",
    "for doc in docs:\n",
    "    result = retrieval_grader.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"document\": doc.page_content,\n",
    "        }\n",
    "    )\n",
    "    if result.binary_score == \"yes\":\n",
    "        filtered_docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dce7a1",
   "metadata": {},
   "source": [
    "### ë‹µë³€ ìƒì„±ì„ ìœ„í•œ RAG ì²´ì¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "992ef15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangChain Hubì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°(RAG í”„ë¡¬í”„íŠ¸ëŠ” ììœ ë¡­ê²Œ ìˆ˜ì • ê°€ëŠ¥)\n",
    "prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0)\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<document><content>{doc.page_content}</content><source>{doc.metadata[\"source\"]}</source><page>{doc.metadata[\"page\"]+1}</page></document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# RAG ì²´ì¸ ìƒì„±\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc96e3",
   "metadata": {},
   "source": [
    "ì´ì œ ìƒì„±í•œ `rag_chain` ì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8d16e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¼ì„±ì „ìê°€ ë§Œë“  ìƒì„±í˜• AIì˜ ì´ë¦„ì€ 'ì‚¼ì„± ê°€ìš°ìŠ¤'ì…ë‹ˆë‹¤.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf (page 13)\n"
     ]
    }
   ],
   "source": [
    "# RAG ì²´ì¸ì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ë‹µë³€ ìƒì„±\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9f601",
   "metadata": {},
   "source": [
    "### ë‹µë³€ì˜ Hallucination ì²´ì»¤ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40ec0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬ë¥¼ ìœ„í•œ ë°ì´í„° ëª¨ë¸ ì •ì˜\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í™˜ê° í‰ê°€ê¸° ìƒì„±\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550b7cf",
   "metadata": {},
   "source": [
    "ìƒì„±í•œ `hallucination_grader` ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë‹µë³€ì˜ í™˜ê° ì—¬ë¶€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb593684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='no')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í‰ê°€ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë‹µë³€ì˜ í™˜ê° ì—¬ë¶€ í‰ê°€\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "110eb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary scoring to evaluate the appropriateness of answers to questions\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicate 'yes' or 'no' whether the answer solves the question\"\n",
    "    )\n",
    "\n",
    "\n",
    "# í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ êµ¬ì¡°í™”ëœ LLM í‰ê°€ê¸°ë¥¼ ê²°í•©í•˜ì—¬ ë‹µë³€ í‰ê°€ê¸° ìƒì„±\n",
    "answer_grader = answer_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66a26ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='yes')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í‰ê°€ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ì„ í•´ê²°í•˜ëŠ”ì§€ ì—¬ë¶€ í‰ê°€\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc11dd",
   "metadata": {},
   "source": [
    "### ì¿¼ë¦¬ ì¬ì‘ì„±(Query Rewriter)\n",
    "\n",
    "- ê²€ì¦ì„ í•˜ê¸° ìœ„í•´ì„œ. \n",
    "- ì§ˆì˜ì–´í•˜ê³  ê´€ë ¨ì´ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ íŒë‹¨ì„ í•´ì„œ.\n",
    "- ë‹µë³€ì´ ì—°ê´€ì„±ì´ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9df325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# Query Rewriter í”„ë¡¬í”„íŠ¸ ì •ì˜(ììœ ë¡­ê²Œ ìˆ˜ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤)\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "# Query Rewriter í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Query Rewriter ìƒì„±\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd3e83",
   "metadata": {},
   "source": [
    "ìƒì„±í•œ `question_rewriter` ì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ê°œì„ ëœ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6eb92e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì‚¼ì„±ì „ìê°€ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ëª…ì¹­ì€ ë¬´ì—‡ì¸ê°€ìš”?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì¬ì‘ì„±ê¸°ì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ê°œì„ ëœ ì§ˆë¬¸ ìƒì„±\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5ee42",
   "metadata": {},
   "source": [
    "### ì›¹ ê²€ìƒ‰ ë„êµ¬\n",
    "\n",
    "**ì›¹ ê²€ìƒ‰ ë„êµ¬**ëŠ” **Adaptive RAG**ì˜ ì¤‘ìš”í•œ êµ¬ì„± ìš”ì†Œë¡œ, ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ì‚¬ìš©ìê°€ ìµœì‹  ì´ë²¤íŠ¸ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì— ëŒ€í•´ ì‹ ì†í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì–»ì„ ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì„¤ì •**: ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì„¤ì •í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "- **ê²€ìƒ‰ ìˆ˜í–‰**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›¹ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "- **ê²°ê³¼ ë¶„ì„**: ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e004263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬ ìƒì„±\n",
    "web_search_tool = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d60abe",
   "metadata": {},
   "source": [
    "ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c13be8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1) - í…Œë””ë…¸íŠ¸', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-01/', 'content': 'â‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€ â‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ â‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ â‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1) 2023ë…„ 09ì›” 28ì¼ 5 ë¶„ ì†Œìš” ëª©ì°¨ ğŸŒ± ë­ì²´ì¸ì˜ ì£¼ìš” ê¸°ëŠ¥ ğŸŒ± í™˜ê²½ì„¤ì • API KEY ë°œê¸‰ ëª¨ë“ˆ ì„¤ì¹˜(openai, langchain) ğŸ”¥ ChatOpenAI ğŸ”¥ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ í™œìš© LLMChain ê°ì²´ â‘  run() â‘¡ apply() â‘¢ generate() â‘£ 2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ ì•ˆì— ì •ì˜ â‘¤ ìŠ¤íŠ¸ë¦¬ë°(streaming) ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì¸ ë­ì²´ì¸(LangChain) ì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ ë‹¤ë¤„ë³´ê³ ì í•©ë‹ˆë‹¤. íŠœí† ë¦¬ì–¼ì€ ì‹œë¦¬ì¦ˆ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´, ì‹œë¦¬ì¦ˆë¥¼ ê±°ë“­í•˜ë©´ì„œ ë­ì²´ì¸(LangChain) ì„ í†µí•´ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì€ ë”ìš± ê°„ê²°í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ë¡  ëŠ¥ë ¥: ì œê³µëœ ë¬¸ë§¥ì— ê¸°ë°˜í•˜ì—¬ ì–´ë–¤ ëŒ€ë‹µì„ í• ì§€, ë˜ëŠ” ì–´ë– í•œ ì•¡ì…˜ì„ ì·¨í• ì§€ì— ëŒ€í•œ ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. íŠ¹íˆ, ì´ëŸ¬í•œ ì‚¬ìš© ì¤€ë¹„ëœ ì²´ì¸ì€ ì´ˆë³´ìë„ ë­ì²´ì¸ì„ ì‰½ê²Œ ì‹œì‘í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ë©°, ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê³„íší•˜ëŠ” ì „ë¬¸ê°€ë“¤ì€ ê¸°ì¡´ ì²´ì¸ì„ ì†ì‰½ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ê±°ë‚˜ ìƒˆë¡­ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.', 'score': 0.6506676, 'raw_content': \"ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1) - í…Œë””ë…¸íŠ¸\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\ní…Œë””ë…¸íŠ¸ ë°ì´í„°ì™€ ì¸ê³µì§€ëŠ¥ì„ ì¢‹ì•„í•˜ëŠ” ê°œë°œì ë…¸íŠ¸\\n\\nê²€ìƒ‰\\nì¹´í…Œê³ ë¦¬\\níƒœê·¸\\nì—°ë„\\nê°•ì˜\\nì–´ë°”ì›ƒë¯¸\\n\\ní† ê¸€ ë©”ë‰´\\n\\nHome \\n/3.  Langchain \\n/5.  ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1)\\n\\nğŸ”¥ì•Œë¦¼ğŸ”¥\\nâ‘  í…Œë””ë…¸íŠ¸ ìœ íŠœë¸Œ - êµ¬ê²½í•˜ëŸ¬ ê°€ê¸°!\\nâ‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€\\nâ‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ\\nâ‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ\\nâ‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ\\në­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1)\\n2023ë…„ 09ì›” 28ì¼ 5 ë¶„ ì†Œìš”\\nëª©ì°¨\\n\\nğŸŒ± ë­ì²´ì¸ì˜ ì£¼ìš” ê¸°ëŠ¥\\nğŸŒ± í™˜ê²½ì„¤ì •\\nAPI KEY ë°œê¸‰\\nëª¨ë“ˆ ì„¤ì¹˜(openai, langchain)\\n\\n\\nğŸ”¥ ChatOpenAI\\nğŸ”¥ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ í™œìš©\\nLLMChain ê°ì²´\\nâ‘  run()\\nâ‘¡ apply()\\nâ‘¢ generate()\\nâ‘£ 2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ ì•ˆì— ì •ì˜\\nâ‘¤ ìŠ¤íŠ¸ë¦¬ë°(streaming)\\n\\n\\n\\nì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì¸ ë­ì²´ì¸(LangChain) ì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ ë‹¤ë¤„ë³´ê³ ì í•©ë‹ˆë‹¤.\\níŠœí† ë¦¬ì–¼ì€ ì‹œë¦¬ì¦ˆ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´, ì‹œë¦¬ì¦ˆë¥¼ ê±°ë“­í•˜ë©´ì„œ ë­ì²´ì¸(LangChain) ì„ í†µí•´ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì€ ë”ìš± ê°„ê²°í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nğŸŒ± ë­ì²´ì¸ì˜ ì£¼ìš” ê¸°ëŠ¥\\në­ì²´ì¸ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°–ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në¬¸ë§¥ ì¸ì‹: ì–¸ì–´ ëª¨ë¸ê³¼ ë‹¤ì–‘í•œ ë¬¸ë§¥ ì†ŒìŠ¤(í”„ë¡¬í”„íŠ¸ ì§€ì‹œ, ì˜ˆì œ, ì‘ë‹µì˜ ê·¼ê±° ë‚´ìš© ë“±)ë¥¼ ì—°ë™í•˜ë©°, ì‚¬ìš©ìì˜ ë¬¸ë§¥ì„ ì •í™•íˆ ì´í•´í•©ë‹ˆë‹¤.\\nì¶”ë¡  ëŠ¥ë ¥: ì œê³µëœ ë¬¸ë§¥ì— ê¸°ë°˜í•˜ì—¬ ì–´ë–¤ ëŒ€ë‹µì„ í• ì§€, ë˜ëŠ” ì–´ë– í•œ ì•¡ì…˜ì„ ì·¨í• ì§€ì— ëŒ€í•œ ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n\\në­ì²´ì¸ì˜ ê°€ì¹˜\\në­ì²´ì¸ì˜ í•µì‹¬ì ì¸ ê°€ì¹˜ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆì§€ë§Œ, ê·¸ ì¤‘ì—ì„œë„ ë‘ ê°€ì§€ ì£¼ìš”í•œ ì ì„ ê¼½ìë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\nêµ¬ì„± ìš”ì†Œ: ì‚¬ìš©ìëŠ” ì–¸ì–´ ëª¨ë¸ê³¼ì˜ ìƒí˜¸ì‘ìš©ì„ ìœ„í•´ ë‹¤ì–‘í•œ êµ¬ì„± ìš”ì†Œì™€ ì¶”ìƒí™”ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†ŒëŠ” ê°œë³„ì ìœ¼ë¡œ, ë˜ëŠ” ë­ì²´ì¸ í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ëª¨ë“ˆì‹ìœ¼ë¡œ ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì‚¬ìš© ì¤€ë¹„ëœ ì²´ì¸: íŠ¹ì • ê³ ìˆ˜ì¤€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë¯¸ë¦¬ ì¡°ë¦½ëœ êµ¬ì„± ìš”ì†Œì˜ íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤.\\n\\níŠ¹íˆ, ì´ëŸ¬í•œ ì‚¬ìš© ì¤€ë¹„ëœ ì²´ì¸ì€ ì´ˆë³´ìë„ ë­ì²´ì¸ì„ ì‰½ê²Œ ì‹œì‘í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ë©°, ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê³„íší•˜ëŠ” ì „ë¬¸ê°€ë“¤ì€ ê¸°ì¡´ ì²´ì¸ì„ ì†ì‰½ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ê±°ë‚˜ ìƒˆë¡­ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.\\nğŸŒ± í™˜ê²½ì„¤ì •\\nAPI KEY ë°œê¸‰\\në¨¼ì €, openai ì˜ API KEY ë¥¼ ë°œê¸‰ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤. ë°œê¸‰ì€ ë‹¤ìŒì˜ ì ˆì°¨ë¥¼ í†µí•´ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nhttps://platform.openai.com/account/api-keys ë¡œ ì ‘ì†í•©ë‹ˆë‹¤.\\n\\nLog in ë²„íŠ¼ì„ í´ë¦­ í›„ ê³„ì •ì— ë¡œê·¸ì¸ í•©ë‹ˆë‹¤. ê³„ì •ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì€ ê²½ìš°ì—ëŠ” Sign up ìœ¼ë¡œ íšŒì›ê°€ì… í›„ ë¡œê·¸ì¸ í•©ë‹ˆë‹¤.\\n\\n\\n\\nâ€œCreate new secret keyâ€ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒˆë¡œìš´ í‚¤ë¥¼ ë°œê¸‰í•©ë‹ˆë‹¤.\\n\\n\\n\\nName ì—ëŠ” ë°œê¸‰í•˜ëŠ” í‚¤ì— ëŒ€í•œ ë³„ì¹­ì„ ì…ë ¥í•©ë‹ˆë‹¤.\\n\\n\\n\\nìƒˆë¡­ê²Œ ë°œê¸‰í•œ í‚¤ë¥¼ ë³µì‚¬í•©ë‹ˆë‹¤. ìƒì–´ë²„ë¦¬ë©´ ë‹¤ì‹œ ë°œê¸‰í•˜ì—¬ì•¼ í•˜ë¯€ë¡œ, ì•ˆì „í•œ ê³³ì— ì €ì¥í•´ ë‘¡ë‹ˆë‹¤.\\n\\n\\nëª¨ë“ˆ ì„¤ì¹˜(openai, langchain)\\npip ëª…ë ¹ì–´ë¡œ ëª¨ë“ˆì„ ì„¤ì¹˜ í•©ë‹ˆë‹¤. ì•„ë‚˜ì½˜ë‹¤ ê°€ìƒí™˜ê²½ì—ì„œ ì„¤ì¹˜í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.\\n```\\nopenai íŒŒì´ì¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜\\npip install openai langchain\\n```\\në¨¼ì €, ì„¤ì¹˜í•œ openai ëª¨ë“ˆì„ import í•œ ë’¤, ë°œê¸‰ë°›ì€ API KEYë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•©ë‹ˆë‹¤.\\n```\\nimport os\\nos.environ['OPENAI_API_KEY'] = 'OPENAI API KEY ì…ë ¥'\\n```\\nì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\\n```\\nimport openai\\nmodel_list = sorted([m['id'] for m in openai.Model.list()['data']])\\nfor m in model_list:\\n    print(m)\\n```\\nada\\nada-code-search-code\\nada-code-search-text\\nada-search-document\\nada-search-query\\nada-similarity\\nbabbage\\nbabbage-002\\nbabbage-code-search-code\\nbabbage-code-search-text\\nbabbage-search-document\\nbabbage-search-query\\nbabbage-similarity\\ncode-davinci-edit-001\\ncode-search-ada-code-001\\ncode-search-ada-text-001\\ncode-search-babbage-code-001\\ncode-search-babbage-text-001\\ncurie\\ncurie-instruct-beta\\ncurie-search-document\\ncurie-search-query\\ncurie-similarity\\ndavinci\\ndavinci-002\\ndavinci-instruct-beta\\ndavinci-search-document\\ndavinci-search-query\\ndavinci-similarity\\ngpt-3.5-turbo\\ngpt-3.5-turbo-0301\\ngpt-3.5-turbo-0613\\ngpt-3.5-turbo-16k\\ngpt-3.5-turbo-16k-0613\\ngpt-3.5-turbo-instruct\\ngpt-3.5-turbo-instruct-0914\\ngpt-4\\ngpt-4-0314\\ngpt-4-0613\\ntext-ada-001\\ntext-babbage-001\\ntext-curie-001\\ntext-davinci-001\\ntext-davinci-002\\ntext-davinci-003\\ntext-davinci-edit-001\\ntext-embedding-ada-002\\ntext-search-ada-doc-001\\ntext-search-ada-query-001\\ntext-search-babbage-doc-001\\ntext-search-babbage-query-001\\ntext-search-curie-doc-001\\ntext-search-curie-query-001\\ntext-search-davinci-doc-001\\ntext-search-davinci-query-001\\ntext-similarity-ada-001\\ntext-similarity-babbage-001\\ntext-similarity-curie-001\\ntext-similarity-davinci-001\\nwhisper-1\\nğŸ”¥ ChatOpenAI\\nOpenAI ì‚¬ì˜ ì±„íŒ… ì „ìš© Large Language Model(llm) ì…ë‹ˆë‹¤.\\nê°ì²´ë¥¼ ìƒì„±í•  ë•Œ ë‹¤ìŒì„ ì˜µì…˜ ê°’ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜µì…˜ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\ntemperature\\n\\nì‚¬ìš©í•  ìƒ˜í”Œë§ ì˜¨ë„ëŠ” 0ê³¼ 2 ì‚¬ì´ì—ì„œ ì„ íƒí•©ë‹ˆë‹¤. 0.8ê³¼ ê°™ì€ ë†’ì€ ê°’ì€ ì¶œë ¥ì„ ë” ë¬´ì‘ìœ„í•˜ê²Œ ë§Œë“¤ê³ , 0.2ì™€ ê°™ì€ ë‚®ì€ ê°’ì€ ì¶œë ¥ì„ ë” ì§‘ì¤‘ë˜ê³  ê²°ì •ë¡ ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.\\n\\nmax_tokens\\n\\nì±„íŒ… ì™„ì„±ì—ì„œ ìƒì„±í•  í† í°ì˜ ìµœëŒ€ ê°œìˆ˜ì…ë‹ˆë‹¤.\\n\\nmodel_name: ì ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸\\n\\n\\ngpt-3.5-turbo\\n\\n\\ngpt-3.5-turbo-0301\\n\\n\\ngpt-3.5-turbo-0613\\n\\n\\ngpt-3.5-turbo-16k\\n\\n\\ngpt-3.5-turbo-16k-0613\\n\\n\\ngpt-3.5-turbo-instruct\\n\\n\\ngpt-3.5-turbo-instruct-0914\\n\\n\\ngpt-4\\n\\n\\ngpt-4-0314\\n\\n\\ngpt-4-0613\\n\\n\\n```\\nfrom langchain.chat_models import ChatOpenAI\\nê°ì²´ ìƒì„±\\nllm = ChatOpenAI(temperature=0,               # ì°½ì˜ì„± (0.0 ~ 2.0) \\n                 max_tokens=2048,             # ìµœëŒ€ í† í°ìˆ˜\\n                 model_name='gpt-3.5-turbo',  # ëª¨ë¸ëª…\\n                )\\nì§ˆì˜ë‚´ìš©\\nquestion = 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ë­ì•¼?'\\nì§ˆì˜\\nprint(f'[ë‹µë³€]: {llm.predict(question)}')\\n```\\n[ë‹µë³€]: ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\\nğŸ”¥ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ í™œìš©\\nPromptTemplate\\n\\n\\nì‚¬ìš©ìì˜ ì…ë ¥ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ ë§Œë“œëŠ” ë° ì‚¬ìš©ë˜ëŠ” í…œí”Œë¦¿ì…ë‹ˆë‹¤\\n\\n\\nì‚¬ìš©ë²•\\n\\n\\ntemplate: í…œí”Œë¦¿ ë¬¸ìì—´ì…ë‹ˆë‹¤. ì´ ë¬¸ìì—´ ë‚´ì—ì„œ ì¤‘ê´„í˜¸ {}ëŠ” ë³€ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n\\n\\ninput_variables: ì¤‘ê´„í˜¸ ì•ˆì— ë“¤ì–´ê°ˆ ë³€ìˆ˜ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜í•©ë‹ˆë‹¤.\\n\\n\\n\\n\\ninput_variables\\n\\n\\ninput_variablesëŠ” PromptTemplateì—ì„œ ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ì˜ ì´ë¦„ì„ ì •ì˜í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\\n\\n\\nì‚¬ìš©ë²•: ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€ìˆ˜ ì´ë¦„ì„ ì •ì˜í•©ë‹ˆë‹¤.\\n\\n\\n```\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.chains import LLMChain\\nì§ˆë¬¸ í…œí”Œë¦¿ í˜•ì‹ ì •ì˜\\ntemplate = '{country}ì˜ ìˆ˜ë„ëŠ” ë­ì•¼?'\\ní…œí”Œë¦¿ ì™„ì„±\\nprompt = PromptTemplate(template=template, input_variables=['country'])\\n```\\nLLMChain ê°ì²´\\nLLMChain\\n\\n\\nLLMChainì€ íŠ¹ì • PromptTemplateì™€ ì—°ê²°ëœ ì²´ì¸ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\\n\\n\\nì‚¬ìš©ë²•\\n\\n\\nprompt: ì•ì„œ ì •ì˜í•œ PromptTemplate ê°ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\\n\\n\\nllm: ì–¸ì–´ ëª¨ë¸ì„ ë‚˜íƒ€ë‚´ë©°, ì´ ì˜ˆì‹œì—ì„œëŠ” ì´ë¯¸ ì–´ë”˜ê°€ì—ì„œ ì •ì˜ëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\\n\\n\\n\\n\\n```\\nì—°ê²°ëœ ì²´ì¸(Chain)ê°ì²´ ìƒì„±\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\nâ‘  run()\\nrun() í•¨ìˆ˜ë¡œ í…œí”Œë¦¿ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰\\n```\\nì²´ì¸ ì‹¤í–‰: run()\\nprint(llm_chain.run(country='ì¼ë³¸'))\\n```\\nì¼ë³¸ì˜ ìˆ˜ë„ëŠ” ë„ì¿„ì…ë‹ˆë‹¤.\\n```\\nì²´ì¸ ì‹¤í–‰: run()\\nprint(llm_chain.run(country='ìºë‚˜ë‹¤'))\\n```\\nìºë‚˜ë‹¤ì˜ ìˆ˜ë„ëŠ” ì˜¤íƒ€ì™€(Ottawa)ì…ë‹ˆë‹¤.\\nâ‘¡ apply()\\napply() í•¨ìˆ˜ë¡œ ì—¬ëŸ¬ê°œì˜ ì…ë ¥ì„ í•œ ë²ˆì— ì‹¤í–‰\\n```\\ninput_list = [\\n    {'country': 'í˜¸ì£¼'},\\n    {'country': 'ì¤‘êµ­'},\\n    {'country': 'ë„¤ëœë€ë“œ'}\\n]\\nllm_chain.apply(input_list)\\n```\\n[{'text': 'í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.'},\\n {'text': 'ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.'},\\n {'text': 'ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.'}]\\ntext í‚¤ ê°’ìœ¼ë¡œ ê²°ê³¼ ë­‰ì¹˜ê°€ ë°˜í™˜ë˜ì—ˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì´ë¥¼ ë°˜ë³µë¬¸ìœ¼ë¡œ ì¶œë ¥í•œë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n```\\ninput_list ì— ëŒ€í•œ ê²°ê³¼ ë°˜í™˜\\nresult = llm_chain.apply(input_list)\\në°˜ë³µë¬¸ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥\\nfor res in result:\\n    print(res['text'].strip())\\n```\\ní˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.\\nì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.\\në„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.\\nâ‘¢ generate()\\ngenerate() ëŠ” ë¬¸ìì—´ ëŒ€ì‹ ì— LLMResultë¥¼ ë°˜í™˜í•˜ëŠ” ì ì„ ì œì™¸í•˜ê³ ëŠ” applyì™€ ìœ ì‚¬í•©ë‹ˆë‹¤.\\nLLMResultëŠ” í† í° ì‚¬ìš©ëŸ‰ê³¼ ì¢…ë£Œ ì´ìœ ì™€ ê°™ì€ ìœ ìš©í•œ ìƒì„± ì •ë³´ë¥¼ ìì£¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\\n```\\ninput_list ì— ëŒ€í•œ ê²°ê³¼ ë°˜í™˜\\ngenerated_result = llm_chain.generate(input_list)\\nprint(generated_result)\\n```\\ngenerations=[[ChatGeneration(text='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))], [ChatGeneration(text='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))], [ChatGeneration(text='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\në‹µë³€ ì¶œë ¥\\ngenerated_result.generations\\n```\\n[[ChatGeneration(text='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))]]\\n```\\ní† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥\\ngenerated_result.llm_output\\n```\\n{'token_usage': {'prompt_tokens': 58,\\n  'completion_tokens': 57,\\n  'total_tokens': 115},\\n 'model_name': 'gpt-3.5-turbo'}\\n```\\nrun ID ì¶œë ¥\\ngenerated_result.run\\n```\\n[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')),\\n RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')),\\n RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\në‹µë³€ ì¶œë ¥\\nfor gen in generated_result.generations:\\n    print(gen[0].text.strip())\\n```\\ní˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.\\nì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.\\në„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.\\nâ‘£ 2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ ì•ˆì— ì •ì˜\\n2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ í…œí”Œë¦¿ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì´ë²ˆì—ëŠ” 2ê°œ ì´ìƒì˜ ë³€ìˆ˜(input_variables) ë¥¼ í™œìš©í•˜ì—¬ í…œí”Œë¦¿ êµ¬ì„±ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤.\\n```\\nì§ˆë¬¸ í…œí”Œë¦¿ í˜•ì‹ ì •ì˜\\ntemplate = '{area1} ì™€ {area2} ì˜ ì‹œì°¨ëŠ” ëª‡ì‹œê°„ì´ì•¼?'\\ní…œí”Œë¦¿ ì™„ì„±\\nprompt = PromptTemplate(template=template, input_variables=['area1', 'area2'])\\nì—°ê²°ëœ ì²´ì¸(Chain)ê°ì²´ ìƒì„±\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n```\\nì²´ì¸ ì‹¤í–‰: run()\\nprint(llm_chain.run(area1='ì„œìš¸', area2='íŒŒë¦¬'))\\n```\\nì„œìš¸ê³¼ íŒŒë¦¬ì˜ ì‹œì°¨ëŠ” 8ì‹œê°„ì…ë‹ˆë‹¤. ì„œìš¸ì´ íŒŒë¦¬ë³´ë‹¤ 8ì‹œê°„ ì•ì„œ ìˆìŠµë‹ˆë‹¤.\\n```\\ninput_list = [\\n    {'area1': 'íŒŒë¦¬', 'area2': 'ë‰´ìš•'},\\n    {'area1': 'ì„œìš¸', 'area2': 'í•˜ì™€ì´'},\\n    {'area1': 'ì¼„ë²„ë¼', 'area2': 'ë² ì´ì§•'}\\n]\\në°˜ë³µë¬¸ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥\\nresult = llm_chain.apply(input_list)\\nfor res in result:\\n    print(res['text'].strip())\\n```\\níŒŒë¦¬ì™€ ë‰´ìš•ì˜ ì‹œì°¨ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 6ì‹œê°„ì…ë‹ˆë‹¤. íŒŒë¦¬ê°€ ë‰´ìš•ë³´ë‹¤ 6ì‹œê°„ ì•ì„œ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŒŒë¦¬ê°€ ì˜¤ì „ 9ì‹œë¼ë©´ ë‰´ìš•ì€ ì˜¤ì „ 3ì‹œì…ë‹ˆë‹¤.\\nì„œìš¸ê³¼ í•˜ì™€ì´ì˜ ì‹œì°¨ëŠ” ì„œìš¸ì´ í•˜ì™€ì´ë³´ë‹¤ 19ì‹œê°„ ë¹ ë¦…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì„œìš¸ì´ ì˜¤ì „ 9ì‹œë¼ë©´ í•˜ì™€ì´ëŠ” ì „ë‚  ì˜¤í›„ 2ì‹œì…ë‹ˆë‹¤.\\nì¼„ë²„ë¼ì™€ ë² ì´ì§•ì˜ ì‹œì°¨ëŠ” 2ì‹œê°„ì…ë‹ˆë‹¤. ì¼„ë²„ë¼ëŠ” ì˜¤ìŠ¤íŠ¸ë ˆì¼ë¦¬ì•„ì˜ ìˆ˜ë„ë¡œ UTC+10 ì‹œê°„ëŒ€ì— ìœ„ì¹˜í•˜ê³ , ë² ì´ì§•ì€ ì¤‘êµ­ì˜ ìˆ˜ë„ë¡œ UTC+8 ì‹œê°„ëŒ€ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.\\nâ‘¤ ìŠ¤íŠ¸ë¦¬ë°(streaming)\\nìŠ¤íŠ¸ë¦¬ë° ì˜µì…˜ì€ ì§ˆì˜ì— ëŒ€í•œ ë‹µë³€ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\\në‹¤ìŒê³¼ ê°™ì´ streaming=True ë¡œ ì„¤ì •í•˜ê³  ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹µë³€ì„ ë°›ê¸° ìœ„í•œ StreamingStdOutCallbackHandler() ì„ ì½œë°±ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.\\n```\\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\\nê°ì²´ ìƒì„±\\nllm = ChatOpenAI(temperature=0,               # ì°½ì˜ì„± (0.0 ~ 2.0) \\n                 max_tokens=2048,             # ìµœëŒ€ í† í°ìˆ˜\\n                 model_name='gpt-3.5-turbo',  # ëª¨ë¸ëª…\\n                 streaming=True,            \\n                 callbacks=[StreamingStdOutCallbackHandler()]\\n                )\\n```\\n```\\nì§ˆì˜ë‚´ìš©\\nquestion = 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ë­ì•¼?'\\nìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹µë³€ ì¶œë ¥\\nresponse = llm.predict(question)\\n```\\nëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\\níƒœê·¸: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, ë­ì²´ì¸, ë­ì²´ì¸ íŠœí† ë¦¬ì–¼\\nì¹´í…Œê³ ë¦¬: langchain\\nì—…ë°ì´íŠ¸: 2023ë…„ 09ì›” 28ì¼\\nê³µìœ í•˜ê¸°\\nTwitter Facebook LinkedIn\\nì´ì „ ë‹¤ìŒ\\nëŒ“ê¸€ë‚¨ê¸°ê¸°\\nì°¸ê³ \\npoetry ì˜ ê±°ì˜ ëª¨ë“ ê²ƒ (íŠœí† ë¦¬ì–¼)\\n2024ë…„ 03ì›” 30ì¼ 5 ë¶„ ì†Œìš”\\nPython ê°œë°œì— ìˆì–´ì„œ poetryëŠ” ë§¤ìš° ê°•ë ¥í•œ ë„êµ¬ë¡œ, í”„ë¡œì íŠ¸ì˜ ì˜ì¡´ì„± ê´€ë¦¬ì™€ íŒ¨í‚¤ì§€ ë°°í¬ë¥¼ ê°„ì†Œí™”í•˜ëŠ” ë° í° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° poetry í™œìš© íŠœí† ë¦¬ì–¼ì„ ì‚´í´ ë³´ê² ìŠµë‹ˆë‹¤.\\nLangGraph Retrieval Agentë¥¼ í™œìš©í•œ ë™ì  ë¬¸ì„œ ê²€ìƒ‰ ë° ì²˜ë¦¬\\n2024ë…„ 03ì›” 06ì¼ 10 ë¶„ ì†Œìš”\\nLangGraph Retrieval AgentëŠ” ì–¸ì–´ ì²˜ë¦¬, AI ëª¨ë¸ í†µí•©, ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬, ê·¸ë˜í”„ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì–¸ì–´ ê¸°ë°˜ AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— í•„ìˆ˜ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤.\\n[Assistants API] Code Interpreter, Retrieval, Functions í™œìš©ë²•\\n2024ë…„ 02ì›” 13ì¼ 35 ë¶„ ì†Œìš”\\nOpenAIì˜ ìƒˆë¡œìš´ Assistants APIëŠ” ëŒ€í™”ì™€ ë”ë¶ˆì–´ ê°•ë ¥í•œ ë„êµ¬ ì ‘ê·¼ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì€ OpenAI Assistants APIë¥¼ í™œìš©í•˜ëŠ” ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤. íŠ¹íˆ, Assistant API ê°€ ì œê³µí•˜ëŠ” ë„êµ¬ì¸ Code Interpreter, Retrieval...\\n[LangChain] ì—ì´ì „íŠ¸(Agent)ì™€ ë„êµ¬(tools)ë¥¼ í™œìš©í•œ ì§€ëŠ¥í˜• ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ\\n2024ë…„ 02ì›” 09ì¼ 41 ë¶„ ì†Œìš”\\nì´ ê¸€ì—ì„œëŠ” LangChain ì˜ Agent í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ê²€ìƒ‰ê³¼ ë°ì´í„° ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. LangSmith ë¥¼ ì‚¬ìš©í•˜ì—¬ Agentì˜ ì¶”ë¡  ë‹¨ê³„ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. Agentê°€ í™œìš©í•  ê²€ìƒ‰ ë„êµ¬(Tavily Search), PDF ê¸°ë°˜ ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„...\\n\\níŒ”ë¡œìš°:\\nYouTube\\nGitHub\\nInstagram\\ní”¼ë“œ\\n\\nÂ© 2024 í…Œë””ë…¸íŠ¸. Powered by Jekyll & Minimal Mistakes.\"}, {'title': 'ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1) - í…Œë””ë…¸íŠ¸', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-01/', 'content': 'â‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€ â‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ â‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ â‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1) 2023ë…„ 09ì›” 28ì¼ 5 ë¶„ ì†Œìš” ëª©ì°¨ ğŸŒ± ë­ì²´ì¸ì˜ ì£¼ìš” ê¸°ëŠ¥ ğŸŒ± í™˜ê²½ì„¤ì • API KEY ë°œê¸‰ ëª¨ë“ˆ ì„¤ì¹˜(openai, langchain) ğŸ”¥ ChatOpenAI ğŸ”¥ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ í™œìš© LLMChain ê°ì²´ â‘  run() â‘¡ apply() â‘¢ generate() â‘£ 2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ ì•ˆì— ì •ì˜ â‘¤ ìŠ¤íŠ¸ë¦¬ë°(streaming) ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì¸ ë­ì²´ì¸(LangChain) ì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ ë‹¤ë¤„ë³´ê³ ì í•©ë‹ˆë‹¤. íŠœí† ë¦¬ì–¼ì€ ì‹œë¦¬ì¦ˆ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´, ì‹œë¦¬ì¦ˆë¥¼ ê±°ë“­í•˜ë©´ì„œ ë­ì²´ì¸(LangChain) ì„ í†µí•´ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì€ ë”ìš± ê°„ê²°í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ë¡  ëŠ¥ë ¥: ì œê³µëœ ë¬¸ë§¥ì— ê¸°ë°˜í•˜ì—¬ ì–´ë–¤ ëŒ€ë‹µì„ í• ì§€, ë˜ëŠ” ì–´ë– í•œ ì•¡ì…˜ì„ ì·¨í• ì§€ì— ëŒ€í•œ ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. íŠ¹íˆ, ì´ëŸ¬í•œ ì‚¬ìš© ì¤€ë¹„ëœ ì²´ì¸ì€ ì´ˆë³´ìë„ ë­ì²´ì¸ì„ ì‰½ê²Œ ì‹œì‘í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ë©°, ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê³„íší•˜ëŠ” ì „ë¬¸ê°€ë“¤ì€ ê¸°ì¡´ ì²´ì¸ì„ ì†ì‰½ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ê±°ë‚˜ ìƒˆë¡­ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.', 'score': 0.6506676, 'raw_content': \"ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1) - í…Œë””ë…¸íŠ¸\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\ní…Œë””ë…¸íŠ¸ ë°ì´í„°ì™€ ì¸ê³µì§€ëŠ¥ì„ ì¢‹ì•„í•˜ëŠ” ê°œë°œì ë…¸íŠ¸\\n\\nê²€ìƒ‰\\nì¹´í…Œê³ ë¦¬\\níƒœê·¸\\nì—°ë„\\nê°•ì˜\\nì–´ë°”ì›ƒë¯¸\\n\\ní† ê¸€ ë©”ë‰´\\n\\nHome \\n/3.  Langchain \\n/5.  ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1)\\n\\nğŸ”¥ì•Œë¦¼ğŸ”¥\\nâ‘  í…Œë””ë…¸íŠ¸ ìœ íŠœë¸Œ - êµ¬ê²½í•˜ëŸ¬ ê°€ê¸°!\\nâ‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€\\nâ‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ\\nâ‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ\\nâ‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ\\në­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1)\\n2023ë…„ 09ì›” 28ì¼ 5 ë¶„ ì†Œìš”\\nëª©ì°¨\\n\\nğŸŒ± ë­ì²´ì¸ì˜ ì£¼ìš” ê¸°ëŠ¥\\nğŸŒ± í™˜ê²½ì„¤ì •\\nAPI KEY ë°œê¸‰\\nëª¨ë“ˆ ì„¤ì¹˜(openai, langchain)\\n\\n\\nğŸ”¥ ChatOpenAI\\nğŸ”¥ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ í™œìš©\\nLLMChain ê°ì²´\\nâ‘  run()\\nâ‘¡ apply()\\nâ‘¢ generate()\\nâ‘£ 2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ ì•ˆì— ì •ì˜\\nâ‘¤ ìŠ¤íŠ¸ë¦¬ë°(streaming)\\n\\n\\n\\nì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì¸ ë­ì²´ì¸(LangChain) ì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ ë‹¤ë¤„ë³´ê³ ì í•©ë‹ˆë‹¤.\\níŠœí† ë¦¬ì–¼ì€ ì‹œë¦¬ì¦ˆ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´, ì‹œë¦¬ì¦ˆë¥¼ ê±°ë“­í•˜ë©´ì„œ ë­ì²´ì¸(LangChain) ì„ í†µí•´ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì€ ë”ìš± ê°„ê²°í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nğŸŒ± ë­ì²´ì¸ì˜ ì£¼ìš” ê¸°ëŠ¥\\në­ì²´ì¸ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°–ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në¬¸ë§¥ ì¸ì‹: ì–¸ì–´ ëª¨ë¸ê³¼ ë‹¤ì–‘í•œ ë¬¸ë§¥ ì†ŒìŠ¤(í”„ë¡¬í”„íŠ¸ ì§€ì‹œ, ì˜ˆì œ, ì‘ë‹µì˜ ê·¼ê±° ë‚´ìš© ë“±)ë¥¼ ì—°ë™í•˜ë©°, ì‚¬ìš©ìì˜ ë¬¸ë§¥ì„ ì •í™•íˆ ì´í•´í•©ë‹ˆë‹¤.\\nì¶”ë¡  ëŠ¥ë ¥: ì œê³µëœ ë¬¸ë§¥ì— ê¸°ë°˜í•˜ì—¬ ì–´ë–¤ ëŒ€ë‹µì„ í• ì§€, ë˜ëŠ” ì–´ë– í•œ ì•¡ì…˜ì„ ì·¨í• ì§€ì— ëŒ€í•œ ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n\\në­ì²´ì¸ì˜ ê°€ì¹˜\\në­ì²´ì¸ì˜ í•µì‹¬ì ì¸ ê°€ì¹˜ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆì§€ë§Œ, ê·¸ ì¤‘ì—ì„œë„ ë‘ ê°€ì§€ ì£¼ìš”í•œ ì ì„ ê¼½ìë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\nêµ¬ì„± ìš”ì†Œ: ì‚¬ìš©ìëŠ” ì–¸ì–´ ëª¨ë¸ê³¼ì˜ ìƒí˜¸ì‘ìš©ì„ ìœ„í•´ ë‹¤ì–‘í•œ êµ¬ì„± ìš”ì†Œì™€ ì¶”ìƒí™”ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†ŒëŠ” ê°œë³„ì ìœ¼ë¡œ, ë˜ëŠ” ë­ì²´ì¸ í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ëª¨ë“ˆì‹ìœ¼ë¡œ ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì‚¬ìš© ì¤€ë¹„ëœ ì²´ì¸: íŠ¹ì • ê³ ìˆ˜ì¤€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë¯¸ë¦¬ ì¡°ë¦½ëœ êµ¬ì„± ìš”ì†Œì˜ íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤.\\n\\níŠ¹íˆ, ì´ëŸ¬í•œ ì‚¬ìš© ì¤€ë¹„ëœ ì²´ì¸ì€ ì´ˆë³´ìë„ ë­ì²´ì¸ì„ ì‰½ê²Œ ì‹œì‘í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ë©°, ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê³„íší•˜ëŠ” ì „ë¬¸ê°€ë“¤ì€ ê¸°ì¡´ ì²´ì¸ì„ ì†ì‰½ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ê±°ë‚˜ ìƒˆë¡­ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.\\nğŸŒ± í™˜ê²½ì„¤ì •\\nAPI KEY ë°œê¸‰\\në¨¼ì €, openai ì˜ API KEY ë¥¼ ë°œê¸‰ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤. ë°œê¸‰ì€ ë‹¤ìŒì˜ ì ˆì°¨ë¥¼ í†µí•´ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nhttps://platform.openai.com/account/api-keys ë¡œ ì ‘ì†í•©ë‹ˆë‹¤.\\n\\nLog in ë²„íŠ¼ì„ í´ë¦­ í›„ ê³„ì •ì— ë¡œê·¸ì¸ í•©ë‹ˆë‹¤. ê³„ì •ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì€ ê²½ìš°ì—ëŠ” Sign up ìœ¼ë¡œ íšŒì›ê°€ì… í›„ ë¡œê·¸ì¸ í•©ë‹ˆë‹¤.\\n\\n\\n\\nâ€œCreate new secret keyâ€ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒˆë¡œìš´ í‚¤ë¥¼ ë°œê¸‰í•©ë‹ˆë‹¤.\\n\\n\\n\\nName ì—ëŠ” ë°œê¸‰í•˜ëŠ” í‚¤ì— ëŒ€í•œ ë³„ì¹­ì„ ì…ë ¥í•©ë‹ˆë‹¤.\\n\\n\\n\\nìƒˆë¡­ê²Œ ë°œê¸‰í•œ í‚¤ë¥¼ ë³µì‚¬í•©ë‹ˆë‹¤. ìƒì–´ë²„ë¦¬ë©´ ë‹¤ì‹œ ë°œê¸‰í•˜ì—¬ì•¼ í•˜ë¯€ë¡œ, ì•ˆì „í•œ ê³³ì— ì €ì¥í•´ ë‘¡ë‹ˆë‹¤.\\n\\n\\nëª¨ë“ˆ ì„¤ì¹˜(openai, langchain)\\npip ëª…ë ¹ì–´ë¡œ ëª¨ë“ˆì„ ì„¤ì¹˜ í•©ë‹ˆë‹¤. ì•„ë‚˜ì½˜ë‹¤ ê°€ìƒí™˜ê²½ì—ì„œ ì„¤ì¹˜í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.\\n```\\nopenai íŒŒì´ì¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜\\npip install openai langchain\\n```\\në¨¼ì €, ì„¤ì¹˜í•œ openai ëª¨ë“ˆì„ import í•œ ë’¤, ë°œê¸‰ë°›ì€ API KEYë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•©ë‹ˆë‹¤.\\n```\\nimport os\\nos.environ['OPENAI_API_KEY'] = 'OPENAI API KEY ì…ë ¥'\\n```\\nì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\\n```\\nimport openai\\nmodel_list = sorted([m['id'] for m in openai.Model.list()['data']])\\nfor m in model_list:\\n    print(m)\\n```\\nada\\nada-code-search-code\\nada-code-search-text\\nada-search-document\\nada-search-query\\nada-similarity\\nbabbage\\nbabbage-002\\nbabbage-code-search-code\\nbabbage-code-search-text\\nbabbage-search-document\\nbabbage-search-query\\nbabbage-similarity\\ncode-davinci-edit-001\\ncode-search-ada-code-001\\ncode-search-ada-text-001\\ncode-search-babbage-code-001\\ncode-search-babbage-text-001\\ncurie\\ncurie-instruct-beta\\ncurie-search-document\\ncurie-search-query\\ncurie-similarity\\ndavinci\\ndavinci-002\\ndavinci-instruct-beta\\ndavinci-search-document\\ndavinci-search-query\\ndavinci-similarity\\ngpt-3.5-turbo\\ngpt-3.5-turbo-0301\\ngpt-3.5-turbo-0613\\ngpt-3.5-turbo-16k\\ngpt-3.5-turbo-16k-0613\\ngpt-3.5-turbo-instruct\\ngpt-3.5-turbo-instruct-0914\\ngpt-4\\ngpt-4-0314\\ngpt-4-0613\\ntext-ada-001\\ntext-babbage-001\\ntext-curie-001\\ntext-davinci-001\\ntext-davinci-002\\ntext-davinci-003\\ntext-davinci-edit-001\\ntext-embedding-ada-002\\ntext-search-ada-doc-001\\ntext-search-ada-query-001\\ntext-search-babbage-doc-001\\ntext-search-babbage-query-001\\ntext-search-curie-doc-001\\ntext-search-curie-query-001\\ntext-search-davinci-doc-001\\ntext-search-davinci-query-001\\ntext-similarity-ada-001\\ntext-similarity-babbage-001\\ntext-similarity-curie-001\\ntext-similarity-davinci-001\\nwhisper-1\\nğŸ”¥ ChatOpenAI\\nOpenAI ì‚¬ì˜ ì±„íŒ… ì „ìš© Large Language Model(llm) ì…ë‹ˆë‹¤.\\nê°ì²´ë¥¼ ìƒì„±í•  ë•Œ ë‹¤ìŒì„ ì˜µì…˜ ê°’ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜µì…˜ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\ntemperature\\n\\nì‚¬ìš©í•  ìƒ˜í”Œë§ ì˜¨ë„ëŠ” 0ê³¼ 2 ì‚¬ì´ì—ì„œ ì„ íƒí•©ë‹ˆë‹¤. 0.8ê³¼ ê°™ì€ ë†’ì€ ê°’ì€ ì¶œë ¥ì„ ë” ë¬´ì‘ìœ„í•˜ê²Œ ë§Œë“¤ê³ , 0.2ì™€ ê°™ì€ ë‚®ì€ ê°’ì€ ì¶œë ¥ì„ ë” ì§‘ì¤‘ë˜ê³  ê²°ì •ë¡ ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.\\n\\nmax_tokens\\n\\nì±„íŒ… ì™„ì„±ì—ì„œ ìƒì„±í•  í† í°ì˜ ìµœëŒ€ ê°œìˆ˜ì…ë‹ˆë‹¤.\\n\\nmodel_name: ì ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸\\n\\n\\ngpt-3.5-turbo\\n\\n\\ngpt-3.5-turbo-0301\\n\\n\\ngpt-3.5-turbo-0613\\n\\n\\ngpt-3.5-turbo-16k\\n\\n\\ngpt-3.5-turbo-16k-0613\\n\\n\\ngpt-3.5-turbo-instruct\\n\\n\\ngpt-3.5-turbo-instruct-0914\\n\\n\\ngpt-4\\n\\n\\ngpt-4-0314\\n\\n\\ngpt-4-0613\\n\\n\\n```\\nfrom langchain.chat_models import ChatOpenAI\\nê°ì²´ ìƒì„±\\nllm = ChatOpenAI(temperature=0,               # ì°½ì˜ì„± (0.0 ~ 2.0) \\n                 max_tokens=2048,             # ìµœëŒ€ í† í°ìˆ˜\\n                 model_name='gpt-3.5-turbo',  # ëª¨ë¸ëª…\\n                )\\nì§ˆì˜ë‚´ìš©\\nquestion = 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ë­ì•¼?'\\nì§ˆì˜\\nprint(f'[ë‹µë³€]: {llm.predict(question)}')\\n```\\n[ë‹µë³€]: ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\\nğŸ”¥ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ í™œìš©\\nPromptTemplate\\n\\n\\nì‚¬ìš©ìì˜ ì…ë ¥ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ ë§Œë“œëŠ” ë° ì‚¬ìš©ë˜ëŠ” í…œí”Œë¦¿ì…ë‹ˆë‹¤\\n\\n\\nì‚¬ìš©ë²•\\n\\n\\ntemplate: í…œí”Œë¦¿ ë¬¸ìì—´ì…ë‹ˆë‹¤. ì´ ë¬¸ìì—´ ë‚´ì—ì„œ ì¤‘ê´„í˜¸ {}ëŠ” ë³€ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n\\n\\ninput_variables: ì¤‘ê´„í˜¸ ì•ˆì— ë“¤ì–´ê°ˆ ë³€ìˆ˜ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜í•©ë‹ˆë‹¤.\\n\\n\\n\\n\\ninput_variables\\n\\n\\ninput_variablesëŠ” PromptTemplateì—ì„œ ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ì˜ ì´ë¦„ì„ ì •ì˜í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\\n\\n\\nì‚¬ìš©ë²•: ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€ìˆ˜ ì´ë¦„ì„ ì •ì˜í•©ë‹ˆë‹¤.\\n\\n\\n```\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.chains import LLMChain\\nì§ˆë¬¸ í…œí”Œë¦¿ í˜•ì‹ ì •ì˜\\ntemplate = '{country}ì˜ ìˆ˜ë„ëŠ” ë­ì•¼?'\\ní…œí”Œë¦¿ ì™„ì„±\\nprompt = PromptTemplate(template=template, input_variables=['country'])\\n```\\nLLMChain ê°ì²´\\nLLMChain\\n\\n\\nLLMChainì€ íŠ¹ì • PromptTemplateì™€ ì—°ê²°ëœ ì²´ì¸ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\\n\\n\\nì‚¬ìš©ë²•\\n\\n\\nprompt: ì•ì„œ ì •ì˜í•œ PromptTemplate ê°ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\\n\\n\\nllm: ì–¸ì–´ ëª¨ë¸ì„ ë‚˜íƒ€ë‚´ë©°, ì´ ì˜ˆì‹œì—ì„œëŠ” ì´ë¯¸ ì–´ë”˜ê°€ì—ì„œ ì •ì˜ëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\\n\\n\\n\\n\\n```\\nì—°ê²°ëœ ì²´ì¸(Chain)ê°ì²´ ìƒì„±\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\nâ‘  run()\\nrun() í•¨ìˆ˜ë¡œ í…œí”Œë¦¿ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰\\n```\\nì²´ì¸ ì‹¤í–‰: run()\\nprint(llm_chain.run(country='ì¼ë³¸'))\\n```\\nì¼ë³¸ì˜ ìˆ˜ë„ëŠ” ë„ì¿„ì…ë‹ˆë‹¤.\\n```\\nì²´ì¸ ì‹¤í–‰: run()\\nprint(llm_chain.run(country='ìºë‚˜ë‹¤'))\\n```\\nìºë‚˜ë‹¤ì˜ ìˆ˜ë„ëŠ” ì˜¤íƒ€ì™€(Ottawa)ì…ë‹ˆë‹¤.\\nâ‘¡ apply()\\napply() í•¨ìˆ˜ë¡œ ì—¬ëŸ¬ê°œì˜ ì…ë ¥ì„ í•œ ë²ˆì— ì‹¤í–‰\\n```\\ninput_list = [\\n    {'country': 'í˜¸ì£¼'},\\n    {'country': 'ì¤‘êµ­'},\\n    {'country': 'ë„¤ëœë€ë“œ'}\\n]\\nllm_chain.apply(input_list)\\n```\\n[{'text': 'í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.'},\\n {'text': 'ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.'},\\n {'text': 'ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.'}]\\ntext í‚¤ ê°’ìœ¼ë¡œ ê²°ê³¼ ë­‰ì¹˜ê°€ ë°˜í™˜ë˜ì—ˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì´ë¥¼ ë°˜ë³µë¬¸ìœ¼ë¡œ ì¶œë ¥í•œë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n```\\ninput_list ì— ëŒ€í•œ ê²°ê³¼ ë°˜í™˜\\nresult = llm_chain.apply(input_list)\\në°˜ë³µë¬¸ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥\\nfor res in result:\\n    print(res['text'].strip())\\n```\\ní˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.\\nì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.\\në„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.\\nâ‘¢ generate()\\ngenerate() ëŠ” ë¬¸ìì—´ ëŒ€ì‹ ì— LLMResultë¥¼ ë°˜í™˜í•˜ëŠ” ì ì„ ì œì™¸í•˜ê³ ëŠ” applyì™€ ìœ ì‚¬í•©ë‹ˆë‹¤.\\nLLMResultëŠ” í† í° ì‚¬ìš©ëŸ‰ê³¼ ì¢…ë£Œ ì´ìœ ì™€ ê°™ì€ ìœ ìš©í•œ ìƒì„± ì •ë³´ë¥¼ ìì£¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\\n```\\ninput_list ì— ëŒ€í•œ ê²°ê³¼ ë°˜í™˜\\ngenerated_result = llm_chain.generate(input_list)\\nprint(generated_result)\\n```\\ngenerations=[[ChatGeneration(text='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))], [ChatGeneration(text='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))], [ChatGeneration(text='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\në‹µë³€ ì¶œë ¥\\ngenerated_result.generations\\n```\\n[[ChatGeneration(text='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))]]\\n```\\ní† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥\\ngenerated_result.llm_output\\n```\\n{'token_usage': {'prompt_tokens': 58,\\n  'completion_tokens': 57,\\n  'total_tokens': 115},\\n 'model_name': 'gpt-3.5-turbo'}\\n```\\nrun ID ì¶œë ¥\\ngenerated_result.run\\n```\\n[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')),\\n RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')),\\n RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\në‹µë³€ ì¶œë ¥\\nfor gen in generated_result.generations:\\n    print(gen[0].text.strip())\\n```\\ní˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.\\nì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.\\në„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.\\nâ‘£ 2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ ì•ˆì— ì •ì˜\\n2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ í…œí”Œë¦¿ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì´ë²ˆì—ëŠ” 2ê°œ ì´ìƒì˜ ë³€ìˆ˜(input_variables) ë¥¼ í™œìš©í•˜ì—¬ í…œí”Œë¦¿ êµ¬ì„±ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤.\\n```\\nì§ˆë¬¸ í…œí”Œë¦¿ í˜•ì‹ ì •ì˜\\ntemplate = '{area1} ì™€ {area2} ì˜ ì‹œì°¨ëŠ” ëª‡ì‹œê°„ì´ì•¼?'\\ní…œí”Œë¦¿ ì™„ì„±\\nprompt = PromptTemplate(template=template, input_variables=['area1', 'area2'])\\nì—°ê²°ëœ ì²´ì¸(Chain)ê°ì²´ ìƒì„±\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n```\\nì²´ì¸ ì‹¤í–‰: run()\\nprint(llm_chain.run(area1='ì„œìš¸', area2='íŒŒë¦¬'))\\n```\\nì„œìš¸ê³¼ íŒŒë¦¬ì˜ ì‹œì°¨ëŠ” 8ì‹œê°„ì…ë‹ˆë‹¤. ì„œìš¸ì´ íŒŒë¦¬ë³´ë‹¤ 8ì‹œê°„ ì•ì„œ ìˆìŠµë‹ˆë‹¤.\\n```\\ninput_list = [\\n    {'area1': 'íŒŒë¦¬', 'area2': 'ë‰´ìš•'},\\n    {'area1': 'ì„œìš¸', 'area2': 'í•˜ì™€ì´'},\\n    {'area1': 'ì¼„ë²„ë¼', 'area2': 'ë² ì´ì§•'}\\n]\\në°˜ë³µë¬¸ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥\\nresult = llm_chain.apply(input_list)\\nfor res in result:\\n    print(res['text'].strip())\\n```\\níŒŒë¦¬ì™€ ë‰´ìš•ì˜ ì‹œì°¨ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 6ì‹œê°„ì…ë‹ˆë‹¤. íŒŒë¦¬ê°€ ë‰´ìš•ë³´ë‹¤ 6ì‹œê°„ ì•ì„œ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŒŒë¦¬ê°€ ì˜¤ì „ 9ì‹œë¼ë©´ ë‰´ìš•ì€ ì˜¤ì „ 3ì‹œì…ë‹ˆë‹¤.\\nì„œìš¸ê³¼ í•˜ì™€ì´ì˜ ì‹œì°¨ëŠ” ì„œìš¸ì´ í•˜ì™€ì´ë³´ë‹¤ 19ì‹œê°„ ë¹ ë¦…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì„œìš¸ì´ ì˜¤ì „ 9ì‹œë¼ë©´ í•˜ì™€ì´ëŠ” ì „ë‚  ì˜¤í›„ 2ì‹œì…ë‹ˆë‹¤.\\nì¼„ë²„ë¼ì™€ ë² ì´ì§•ì˜ ì‹œì°¨ëŠ” 2ì‹œê°„ì…ë‹ˆë‹¤. ì¼„ë²„ë¼ëŠ” ì˜¤ìŠ¤íŠ¸ë ˆì¼ë¦¬ì•„ì˜ ìˆ˜ë„ë¡œ UTC+10 ì‹œê°„ëŒ€ì— ìœ„ì¹˜í•˜ê³ , ë² ì´ì§•ì€ ì¤‘êµ­ì˜ ìˆ˜ë„ë¡œ UTC+8 ì‹œê°„ëŒ€ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.\\nâ‘¤ ìŠ¤íŠ¸ë¦¬ë°(streaming)\\nìŠ¤íŠ¸ë¦¬ë° ì˜µì…˜ì€ ì§ˆì˜ì— ëŒ€í•œ ë‹µë³€ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\\në‹¤ìŒê³¼ ê°™ì´ streaming=True ë¡œ ì„¤ì •í•˜ê³  ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹µë³€ì„ ë°›ê¸° ìœ„í•œ StreamingStdOutCallbackHandler() ì„ ì½œë°±ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.\\n```\\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\\nê°ì²´ ìƒì„±\\nllm = ChatOpenAI(temperature=0,               # ì°½ì˜ì„± (0.0 ~ 2.0) \\n                 max_tokens=2048,             # ìµœëŒ€ í† í°ìˆ˜\\n                 model_name='gpt-3.5-turbo',  # ëª¨ë¸ëª…\\n                 streaming=True,            \\n                 callbacks=[StreamingStdOutCallbackHandler()]\\n                )\\n```\\n```\\nì§ˆì˜ë‚´ìš©\\nquestion = 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ë­ì•¼?'\\nìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹µë³€ ì¶œë ¥\\nresponse = llm.predict(question)\\n```\\nëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\\níƒœê·¸: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, ë­ì²´ì¸, ë­ì²´ì¸ íŠœí† ë¦¬ì–¼\\nì¹´í…Œê³ ë¦¬: langchain\\nì—…ë°ì´íŠ¸: 2023ë…„ 09ì›” 28ì¼\\nê³µìœ í•˜ê¸°\\nTwitter Facebook LinkedIn\\nì´ì „ ë‹¤ìŒ\\nëŒ“ê¸€ë‚¨ê¸°ê¸°\\nì°¸ê³ \\npoetry ì˜ ê±°ì˜ ëª¨ë“ ê²ƒ (íŠœí† ë¦¬ì–¼)\\n2024ë…„ 03ì›” 30ì¼ 5 ë¶„ ì†Œìš”\\nPython ê°œë°œì— ìˆì–´ì„œ poetryëŠ” ë§¤ìš° ê°•ë ¥í•œ ë„êµ¬ë¡œ, í”„ë¡œì íŠ¸ì˜ ì˜ì¡´ì„± ê´€ë¦¬ì™€ íŒ¨í‚¤ì§€ ë°°í¬ë¥¼ ê°„ì†Œí™”í•˜ëŠ” ë° í° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° poetry í™œìš© íŠœí† ë¦¬ì–¼ì„ ì‚´í´ ë³´ê² ìŠµë‹ˆë‹¤.\\nLangGraph Retrieval Agentë¥¼ í™œìš©í•œ ë™ì  ë¬¸ì„œ ê²€ìƒ‰ ë° ì²˜ë¦¬\\n2024ë…„ 03ì›” 06ì¼ 10 ë¶„ ì†Œìš”\\nLangGraph Retrieval AgentëŠ” ì–¸ì–´ ì²˜ë¦¬, AI ëª¨ë¸ í†µí•©, ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬, ê·¸ë˜í”„ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì–¸ì–´ ê¸°ë°˜ AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— í•„ìˆ˜ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤.\\n[Assistants API] Code Interpreter, Retrieval, Functions í™œìš©ë²•\\n2024ë…„ 02ì›” 13ì¼ 35 ë¶„ ì†Œìš”\\nOpenAIì˜ ìƒˆë¡œìš´ Assistants APIëŠ” ëŒ€í™”ì™€ ë”ë¶ˆì–´ ê°•ë ¥í•œ ë„êµ¬ ì ‘ê·¼ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì€ OpenAI Assistants APIë¥¼ í™œìš©í•˜ëŠ” ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤. íŠ¹íˆ, Assistant API ê°€ ì œê³µí•˜ëŠ” ë„êµ¬ì¸ Code Interpreter, Retrieval...\\n[LangChain] ì—ì´ì „íŠ¸(Agent)ì™€ ë„êµ¬(tools)ë¥¼ í™œìš©í•œ ì§€ëŠ¥í˜• ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ\\n2024ë…„ 02ì›” 09ì¼ 41 ë¶„ ì†Œìš”\\nì´ ê¸€ì—ì„œëŠ” LangChain ì˜ Agent í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ê²€ìƒ‰ê³¼ ë°ì´í„° ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. LangSmith ë¥¼ ì‚¬ìš©í•˜ì—¬ Agentì˜ ì¶”ë¡  ë‹¨ê³„ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. Agentê°€ í™œìš©í•  ê²€ìƒ‰ ë„êµ¬(Tavily Search), PDF ê¸°ë°˜ ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„...\\n\\níŒ”ë¡œìš°:\\nYouTube\\nGitHub\\nInstagram\\ní”¼ë“œ\\n\\nÂ© 2024 í…Œë””ë…¸íŠ¸. Powered by Jekyll & Minimal Mistakes.\"}, {'title': ' - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ - WikiDocs', 'url': 'https://wikidocs.net/book/14314', 'content': \"ëŒ€í™”ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ” RAG ì²´ì¸ CH13 LangChain Expression Language(LCEL) 01. êµ¬ì¡°í™”ëœ ì¶œë ¥ ì²´ì¸(with_structered_output) CH15 í‰ê°€(Evaluations) 01. ì˜¨ë¼ì¸ í‰ê°€ë¥¼ í™œìš©í•œ í‰ê°€ ìë™í™” CH16 ì—ì´ì „íŠ¸(Agent) 01. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with Tools) CH17 LangGraph 01. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m. ì¶œë ¥ëœ ê²°ê³¼ë¥¼ ë¹„êµí–ˆì„ ë•Œ, kiwi tokenizerì„ ì‚¬ìš©í•œ ê²°ê³¼ì™€ kkma, okt ë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ê°€ í° ì°¨ì´ê°€ ì—†ë‹¤ê³  ë´ë„ ë˜ëŠ” ê±´ê°€ìš”? CH01 LangChain ì‹œì‘í•˜ê¸° - NamHyeon, Dec. 8, 2024, 1:17 p.m. ì¢‹ì€ ìë£Œë¥¼ ë¬´ë£Œë¡œ ê³µìœ í•´ ì£¼ì…”ì„œ, ê°ì‚¬í•œ ë§ˆìŒì— 'í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸' ê°•ì˜ ë“±ë¡í–ˆìŠµë‹ˆë‹¤ ! ëŒ€í™” í† í° ë²„í¼ ë©”ëª¨ë¦¬(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\", 'score': 0.5996498, 'raw_content': '<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· - WikiDocs\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· CH01 LangChain ì‹œì‘í•˜ê¸° 01. ì„¤ì¹˜ ì˜ìƒë³´ê³  ë”°ë¼í•˜ê¸° 02. OpenAI API í‚¤ ë°œê¸‰ ë° í…ŒìŠ¤íŠ¸ 03. LangSmith ì¶”ì  ì„¤ì • 04. OpenAI API ì‚¬ìš©(GPT-4o ë©€í‹°ëª¨ë‹¬) 05. LangChain Expression Language(LCEL) 06. LCEL ì¸í„°í˜ì´ìŠ¤ 07. Runnable CH02 í”„ë¡¬í”„íŠ¸(Prompt) 01. í”„ë¡¬í”„íŠ¸(Prompt) 02. í“¨ìƒ· í”„ë¡¬í”„íŠ¸(FewShotPromptTemplate) 03. LangChain Hub 04. ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸(Hubì— ì—…ë¡œë“œ) CH03 ì¶œë ¥ íŒŒì„œ(Output Parsers) 01. Pydantic ì¶œë ¥ íŒŒì„œ(PydanticOutputParser) 02. ì½¤ë§ˆ êµ¬ë¶„ì ì¶œë ¥ íŒŒì„œ(CommaSeparatedListOutputParser) 03. êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ(StructuredOuputParser) 04. JSON ì¶œë ¥ íŒŒì„œ(JsonOutputParser) 05. ë°ì´í„°í”„ë ˆì„ ì¶œë ¥ íŒŒì„œ(PandasDataFrameOutputParser) 06. ë‚ ì§œ í˜•ì‹ ì¶œë ¥ íŒŒì„œ(DatetimeOutputParser) 07. ì—´ê±°í˜• ì¶œë ¥ íŒŒì„œ(EnumOutputParser) 08. ì¶œë ¥ ìˆ˜ì • íŒŒì„œ(OutputFixingParser) CH04 ëª¨ë¸(Model) 01. ë‹¤ì–‘í•œ LLM ëª¨ë¸ í™œìš© 02. ìºì‹±(Cache) 03. ëª¨ë¸ ì§ë ¬í™”(Serialization) - ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° 04. í† í° ì‚¬ìš©ëŸ‰ í™•ì¸ 05. êµ¬ê¸€ ìƒì„± AI(Google Generative AI) 06. í—ˆê¹…í˜ì´ìŠ¤ ì—”ë“œí¬ì¸íŠ¸(HuggingFace Endpoints) 07. í—ˆê¹…í˜ì´ìŠ¤ ë¡œì»¬(HuggingFace Local) 08. í—ˆê¹…í˜ì´ìŠ¤ íŒŒì´í”„ë¼ì¸(HuggingFace Pipeline) 09. ì˜¬ë¼ë§ˆ(Ollama) 10. GPT4ALL 11. ë¹„ë””ì˜¤(Video) ì§ˆì˜ ì‘ë‹µ LLM (Gemini) CH05 ë©”ëª¨ë¦¬(Memory) 01. ëŒ€í™” ë²„í¼ ë©”ëª¨ë¦¬(ConversationBufferMemory) 02. ëŒ€í™” ë²„í¼ ìœˆë„ìš° ë©”ëª¨ë¦¬(ConversationBufferWindowMemory) 03. ëŒ€í™” í† í° ë²„í¼ ë©”ëª¨ë¦¬(ConversationTokenBufferMemory) 04. ëŒ€í™” ì—”í‹°í‹° ë©”ëª¨ë¦¬(ConversationEntityMemory) 05. ëŒ€í™” ì§€ì‹ê·¸ë˜í”„ ë©”ëª¨ë¦¬(ConversationKGMemory) 06. ëŒ€í™” ìš”ì•½ ë©”ëª¨ë¦¬(ConversationSummaryMemory) 07. ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ ë©”ëª¨ë¦¬(VectorStoreRetrieverMemory) 08. LCEL Chain ì— ë©”ëª¨ë¦¬ ì¶”ê°€ 09. SQLite ì— ëŒ€í™”ë‚´ìš© ì €ì¥ 10. RunnableWithMessageHistoryì— ChatMessageHistoryì¶”ê°€ CH06 ë¬¸ì„œ ë¡œë”(Document Loader) 01. ë„íë¨¼íŠ¸(Document) ì˜ êµ¬ì¡° 02. PDF 03. í•œê¸€(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. ì›¹ ë¬¸ì„œ(WebBaseLoader) 09. í…ìŠ¤íŠ¸(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 í…ìŠ¤íŠ¸ ë¶„í• (Text Splitter) 01. ë¬¸ì í…ìŠ¤íŠ¸ ë¶„í• (CharacterTextSplitter) 02. ì¬ê·€ì  ë¬¸ì í…ìŠ¤íŠ¸ ë¶„í• (RecursiveCharacterTextSplitter) 03. í† í° í…ìŠ¤íŠ¸ ë¶„í• (TokenTextSplitter) 04. ì‹œë©˜í‹± ì²­ì»¤(SemanticChunker) 05. ì½”ë“œ ë¶„í• (Python, Markdown, JAVA, C++, C#, GO, JS, Latex ë“±) 06. ë§ˆí¬ë‹¤ìš´ í—¤ë” í…ìŠ¤íŠ¸ ë¶„í• (MarkdownHeaderTextSplitter) 07. HTML í—¤ë” í…ìŠ¤íŠ¸ ë¶„í• (HTMLHeaderTextSplitter) 08. ì¬ê·€ì  JSON ë¶„í• (RecursiveJsonSplitter) CH08 ì„ë² ë”©(Embedding) 01. OpenAIEmbeddings 02. ìºì‹œ ì„ë² ë”©(CacheBackedEmbeddings) 03. í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”©(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL ì„ë² ë”© 07. Llama CPP ì„ë² ë”© CH09 ë²¡í„°ì €ì¥ì†Œ(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 ê²€ìƒ‰ê¸°(Retriever) 01. ë²¡í„°ìŠ¤í† ì–´ ê¸°ë°˜ ê²€ìƒ‰ê¸°(VectorStore-backed Retriever) 02. ë¬¸ë§¥ ì••ì¶• ê²€ìƒ‰ê¸°(ContextualCompressionRetriever) 03. ì•™ìƒë¸” ê²€ìƒ‰ê¸°(EnsembleRetriever) 04. ê¸´ ë¬¸ë§¥ ì¬ì •ë ¬(LongContextReorder) 05. ìƒìœ„ ë¬¸ì„œ ê²€ìƒ‰ê¸°(ParentDocumentRetriever) 06. ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ê¸°(MultiQueryRetriever) 07. ë‹¤ì¤‘ ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ê¸°(MultiVectorRetriever) 08. ì…€í”„ ì¿¼ë¦¬ ê²€ìƒ‰ê¸°(SelfQueryRetriever) 09. ì‹œê°„ ê°€ì¤‘ ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ê¸°(TimeWeightedVectorStoreRetriever) 10. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° 11. Convex Combination(CC) ì ìš©ëœ ì•™ìƒë¸” ê²€ìƒ‰ê¸°(EnsembleRetriever) CH11 ë¦¬ë­ì»¤(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF ë¬¸ì„œ ê¸°ë°˜ QA(Question-Answer) 02. ë„¤ì´ë²„ ë‰´ìŠ¤ê¸°ì‚¬ QA(Question-Answer) 03. RAG ì˜ ê¸°ëŠ¥ë³„ ë‹¤ì–‘í•œ ëª¨ë“ˆ í™œìš©ê¸° 04. RAPTOR: ê¸´ ë¬¸ë§¥ ìš”ì•½(Long Context Summary) 05. ëŒ€í™”ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ” RAG ì²´ì¸ CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable êµ¬ì¡°(ê·¸ë˜í”„) ê²€í†  03. RunnableLambda 04. LLM ì²´ì¸ ë¼ìš°íŒ…(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. ë™ì  ì†ì„± ì§€ì •(configurable_fields, configurable_alternatives) 07. @chain ë°ì½”ë ˆì´í„°ë¡œ Runnable êµ¬ì„± 08. RunnableWithMessageHistory 09. ì‚¬ìš©ì ì •ì˜ ì œë„¤ë ˆì´í„°(generator) 10. Runtime Arguments ë°”ì¸ë”© 11. í´ë°±(fallback) ëª¨ë¸ ì§€ì • CH14 ì²´ì¸(Chains) 01. ë¬¸ì„œ ìš”ì•½ 02. SQL 03. êµ¬ì¡°í™”ëœ ì¶œë ¥ ì²´ì¸(with_structered_output) CH15 í‰ê°€(Evaluations) 01. í•©ì„± í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±(RAGAS) 02. RAGAS ë¥¼ í™œìš©í•œ í‰ê°€ 03. ìƒì„±í•œ í‰ê°€ìš© ë°ì´í„°ì…‹ ì—…ë¡œë“œ(HuggingFace Dataset) 04. LangSmith ë°ì´í„°ì…‹ ìƒì„± 05. LLM-as-Judge 06. ì„ë² ë”© ê¸°ë°˜ í‰ê°€(embedding_distance) 07. ì‚¬ìš©ì ì •ì˜(Custom) LLM í‰ê°€ 08. Rouge, BLEU, METEOR, SemScore ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± í‰ê°€ 09. ì‹¤í—˜(Experiment) í‰ê°€ ë¹„êµ 10. ìš”ì•½(Summary) ë°©ì‹ì˜ í‰ê°€ 11. Groundedness(í• ë£¨ì‹œë„¤ì´ì…˜) í‰ê°€ 12. ì‹¤í—˜ ë¹„êµ(Pairwise Evaluation) 13. ë°˜ë³µ í‰ê°€ 14. ì˜¨ë¼ì¸ í‰ê°€ë¥¼ í™œìš©í•œ í‰ê°€ ìë™í™” CH16 ì—ì´ì „íŠ¸(Agent) 01. ë„êµ¬(Tools) 02. ë„êµ¬ ë°”ì¸ë”©(Binding Tools) 03. ì—ì´ì „íŠ¸(Agent) 04. Claude, Gemini, Ollama, Together.ai ë¥¼ í™œìš©í•œ Agent 05. Iteration ê¸°ëŠ¥ê³¼ ì‚¬ëŒ ê°œì…(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel ë°ì´í„° ë¶„ì„ Agent 08. Toolkits í™œìš© Agent 09. RAG + Image Generator Agent(ë³´ê³ ì„œ ì‘ì„±) 10. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with Tools) CH17 LangGraph 01. í•µì‹¬ ê¸°ëŠ¥ 01. LangGraph ì— ìì£¼ ë“±ì¥í•˜ëŠ” Python ë¬¸ë²•ì´í•´ 02. LangGraphë¥¼ í™œìš©í•œ ì±—ë´‡ êµ¬ì¶• 03. LangGraphë¥¼ í™œìš©í•œ Agent êµ¬ì¶• 04. Agent ì— ë©”ëª¨ë¦¬(memory) ì¶”ê°€ 05. ë…¸ë“œì˜ ë‹¨ê³„ë³„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ 06. Human-in-the-loop(ì‚¬ëŒì˜ ê°œì…) 07. ì¤‘ê°„ë‹¨ê³„ ê°œì… ë˜ëŒë¦¼ì„ í†µí•œ ìƒíƒœ ìˆ˜ì •ê³¼ Replay 08. ì‚¬ëŒ(Human)ì—ê²Œ ë¬¼ì–´ë³´ëŠ” ë…¸ë“œ ì¶”ê°€ 09. ë©”ì‹œì§€ ì‚­ì œ(RemoveMessage) 10. ToolNode ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ë°©ë²• 11. ë³‘ë ¬ ë…¸ë“œ ì‹¤í–‰ì„ ìœ„í•œ ë¶„ê¸° ìƒì„± ë°©ë²• 12. ëŒ€í™” ê¸°ë¡ ìš”ì•½ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²• 13. ì„œë¸Œê·¸ë˜í”„ ì¶”ê°€ ë° ì‚¬ìš© ë°©ë²• 14. ì„œë¸Œê·¸ë˜í”„ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ë³€í™˜í•˜ëŠ” ë°©ë²• 15. LangGraph ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì˜ ëª¨ë“  ê²ƒ 02. êµ¬ì¡° ì„¤ê³„ 01. ê¸°ë³¸ ê·¸ë˜í”„ ìƒì„± 02. Naive RAG 03. ê´€ë ¨ì„± ì²´ì»¤(Relevance Checker) ëª¨ë“ˆ ì¶”ê°€ 04. ì›¹ ê²€ìƒ‰ ëª¨ë“ˆ ì¶”ê°€ 05. ì¿¼ë¦¬ ì¬ì‘ì„± ëª¨ë“ˆ ì¶”ê°€ 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. ì—ì´ì „íŠ¸ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜ (ê³ ê° ì‘ëŒ€ ì‹œë‚˜ë¦¬ì˜¤) 02. ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ë©”íƒ€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì—ì´ì „íŠ¸ 03. CRAG(Corrective RAG) 04. Self-RAG 05. ê³„íš í›„ ì‹¤í–‰(Plan-and-Execute) 06. ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—… ë„¤íŠ¸ì›Œí¬(Multi-Agent Collaboration Network) 07. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) 08. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) 09. SQL ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ 10. STORM ê°œë…ì„ ë„ì…í•œ ì—°êµ¬ë¥¼ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ CH18 ê¸°íƒ€ ì •ë³´ 01. StreamEvent íƒ€ì…ë³„ ì •ë¦¬\\nPublished with WikiDocs\\n\\n\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - Langâ€¦\\n\\n\\në„ì„œ ì¦ì • ì´ë²¤íŠ¸ !!\\n\\nWikiDocs\\n\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡·\\n\\nAuthor: í…Œë””ë…¸íŠ¸\\nLast edited by : Jan. 16, 2025, 12:23 a.m.\\nCopyright : \\n2,553 Like; \"ì¶”ì²œ\")\\nì¶”ì²œì€ ê³µìœ í•  ìˆ˜ ìˆëŠ” ë¬´ë£Œ ì „ìì±…ì„ ì§‘í•„í•˜ëŠ”ë° ì •ë§ í° í˜ì´ ë©ë‹ˆë‹¤. \"ì¶”ì²œ\" í•œ ë²ˆì”©ë§Œ ë¶€íƒ ë“œë¦¬ê² ìŠµë‹ˆë‹¤ğŸ™ğŸ™\\nâœ… ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ê°•ì˜\\níŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ - RAG ë¹„ë²•ë…¸íŠ¸\\nâœ… ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ì½”ë“œì €ì¥ì†Œ(GitHub) ğŸ“˜ğŸ–¥ï¸\\nhttps://github.com/teddylee777/langchain-kr\\nâœ… ìœ íŠœë¸Œ \"í…Œë””ë…¸íŠ¸\" ğŸ¥ğŸ“š\\nhttps://www.youtube.com/c/@teddynote\\nâœ… ë°ì´í„° ë¶„ì„ ë¸”ë¡œê·¸ https://teddylee777.github.io\\nâœ… ë¬¸ì˜ teddylee777@gmail.com\\nLICENSE\\nì¸ìš© ë° ì¶œì²˜ í‘œê¸°\\n\\në³¸ ì €ì‘ë¬¼ì„ ë¸”ë¡œê·¸, ìœ íŠœë¸Œ ë“± ì˜¨ë¼ì¸ ë§¤ì²´ì— ì¸ìš©í•˜ì—¬ ê²Œì¬í•  ê²½ìš°, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea ë¼ì´ì„ ìŠ¤ì— ë”°ë¼ ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\\n\\nìƒì—…ì  ì‚¬ìš©ì— ëŒ€í•œ ì‚¬ì „ í˜‘ì˜\\n\\në³¸ ì €ì‘ë¬¼(Wikidocs ë° ê´€ë ¨ ì‹¤ìŠµ ì½”ë“œ í¬í•¨)ì„ ê°•ì˜, ê°•ì—° ë“± ìƒì—…ì  ëª©ì ìœ¼ë¡œ í™œìš©í•˜ê³ ì í•˜ëŠ” ê²½ìš°, ì €ì‘ê¶Œìì™€ì˜ ì‚¬ì „ ì„œë©´ í˜‘ì˜ê°€ í•„ìˆ˜ì ìœ¼ë¡œ ìš”êµ¬ë©ë‹ˆë‹¤. í•´ë‹¹ í˜‘ì˜ëŠ” teddylee777@gmail.comìœ¼ë¡œ ë¬¸ì˜í•˜ì—¬ ì§„í–‰í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në³¸ ì €ì‘ë¬¼ì€ 2024ë…„ í…Œë””ë…¸íŠ¸ì— ì˜í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. \\nëª¨ë“  ê¶Œë¦¬ëŠ” ì €ì‘ê¶Œìì—ê²Œ ìˆìœ¼ë©°, ë³¸ ì €ì‘ë¬¼ì€ Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea ë¼ì´ì„ ìŠ¤ì— ë”°ë¼ ë°°í¬ë©ë‹ˆë‹¤.\\në³¸ ì €ì‘ë¬¼ì˜ ë¬´ë‹¨ ì „ì¬ ë° ì¬ë°°í¬ë¥¼ ê¸ˆì§€í•˜ë©°, ì „ì²´ í˜¹ì€ ì¼ë¶€ë¥¼ ì¸ìš©í•  ê²½ìš° ì¶œì²˜ë¥¼ ëª…í™•íˆ ë°í˜€ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\\në³¸ ë¬¸ì„œëŠ” ë‹¤ë¥¸ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³  ìë£ŒëŠ” ë³¸ ë¬¸ì„œ í•˜ë‹¨ì˜ ì¶œì²˜ ëª©ë¡ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nCopyright (c) í…Œë””ë…¸íŠ¸.\\nReference\\n\\nLangChain Github\\nLangGraph Github\\nLangChain Document\\n\\nRecent Comments (8) Recent Modifications (10) RSS\\n02. ë„¤ì´ë²„ ë‰´ìŠ¤ê¸°ì‚¬ QA(Question-Answer) - ê¹€ë¯¼ê²¸, Feb. 2, 2025, 12:17 p.m.\\n\"bullet points í˜•ì‹ìœ¼ë¡œ ì •ë¦¬\"ì—ì„œ \"ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\" ë¼ê³  ë‚˜ì˜¤ëŠ”ë° ì´ìœ ë¥¼ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? kmk582@naver.com\\n10. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m.\\nì¶œë ¥ëœ ê²°ê³¼ë¥¼ ë¹„êµí–ˆì„ ë•Œ, kiwi tokenizerì„ ì‚¬ìš©í•œ ê²°ê³¼ì™€ kkma, okt ë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ê°€ í° ì°¨ì´ê°€ ì—†ë‹¤ê³  ë´ë„ ë˜ëŠ” ê±´ê°€ìš”?\\nCH01 LangChain ì‹œì‘í•˜ê¸° - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\nì¢‹ì€ ìë£Œë¥¼ ë¬´ë£Œë¡œ ê³µìœ í•´ ì£¼ì…”ì„œ, ê°ì‚¬í•œ ë§ˆìŒì— \\'í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸\\' ê°•ì˜ ë“±ë¡í–ˆìŠµë‹ˆë‹¤ ! ë¬¼ë¡  ì œ í˜„ì—…ì— í•„ìš”í•œ ê¸°ìˆ ì´ë¼ì„œ, ê°•ì˜ ë˜í•œ ê¸°ìœ ë§ˆìŒì— ì‹ ì²­í–ˆêµ¬ìš” ~ ì •ì£¼í–‰ í•´ì„œ, ì°½ê³µì„ ë‚ ì•„ê°€ ë³´ê² ìŠµë‹ˆë‹¤ ^^\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\npython-docxë„ ì„¤ì¹˜í•´ì•¼ í• ê¹Œìš”?\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\n!pip install jq ë¶€ë¶„ì´ ë“¤ì–´ê°€ì•¼ í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤.\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\n<html><head> <meta http-equiv=\"Content-Type\" content=\"text/html\"> </head><body> <span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span> <div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div> <div style=\"position:absolute; border ì´ ë¶€ë¶„ì´ ì¶œë ¥ ê²°ê³¼ê°€ ì•„ë‹ˆë¼ ì½”ë“œì¸ ê²ƒì²˜ëŸ¼ í‘œì‹œë˜ì–´ ìˆë„¤ìš”~\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\nê°ì‚¬íˆ ì˜ ì°¸ê³ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„ì£¼ ì‚¬ì†Œí•œ ì˜¤ê¸°ì´ì§€ë§Œ... 11ë²ˆ Arxiv ë‹¤ìŒì— 12ë²ˆì´ ì™€ì•¼ í•  í…ë°, ì›ë˜ ë„£ìœ¼ì‹œë ¤ë˜ ë‹¤ë¥¸ ëª©ì°¨ê°€ ë¹ ì§„ ê²ƒì¸ì§€ ë°”ë¡œ 13ë²ˆì´ ë‚˜ì™”ë„¤ìš”^^\\n03. ëª¨ë¸ ì§ë ¬í™”(Serialization) - ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° - ë™êµ¬, Sept. 20, 2024, 12:58 p.m.\\nloadsëŠ” ë­ì—ìš”?\\n10. JSON - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n03. ëŒ€í™” í† í° ë²„í¼ ë©”ëª¨ë¦¬(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n05. ì½”ë“œ ë¶„í• (Python, Markdown, JAVA, C++, C#, GO, JS, Latex ë“±) - Jan. 16, 2025, 12:19 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n10. STORM ê°œë…ì„ ë„ì…í•œ ì—°êµ¬ë¥¼ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ - Dec. 23, 2024, 3:16 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n05. ê³„íš í›„ ì‹¤í–‰(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n07. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n08. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n09. SQL ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n\\nNext : CH01 LangChain ì‹œì‘í•˜ê¸°\\n\\n\\nÃ—\\nì±…ê°ˆí”¼\\nì¶”ê°€ ë‹«ê¸°\\n\\nÃ—\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\nâ€» Feedback is delivered to the author by email.\\nClose Send'}, {'title': ' - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ - WikiDocs', 'url': 'https://wikidocs.net/book/14314', 'content': \"ëŒ€í™”ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ” RAG ì²´ì¸ CH13 LangChain Expression Language(LCEL) 01. êµ¬ì¡°í™”ëœ ì¶œë ¥ ì²´ì¸(with_structered_output) CH15 í‰ê°€(Evaluations) 01. ì˜¨ë¼ì¸ í‰ê°€ë¥¼ í™œìš©í•œ í‰ê°€ ìë™í™” CH16 ì—ì´ì „íŠ¸(Agent) 01. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with Tools) CH17 LangGraph 01. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m. ì¶œë ¥ëœ ê²°ê³¼ë¥¼ ë¹„êµí–ˆì„ ë•Œ, kiwi tokenizerì„ ì‚¬ìš©í•œ ê²°ê³¼ì™€ kkma, okt ë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ê°€ í° ì°¨ì´ê°€ ì—†ë‹¤ê³  ë´ë„ ë˜ëŠ” ê±´ê°€ìš”? CH01 LangChain ì‹œì‘í•˜ê¸° - NamHyeon, Dec. 8, 2024, 1:17 p.m. ì¢‹ì€ ìë£Œë¥¼ ë¬´ë£Œë¡œ ê³µìœ í•´ ì£¼ì…”ì„œ, ê°ì‚¬í•œ ë§ˆìŒì— 'í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸' ê°•ì˜ ë“±ë¡í–ˆìŠµë‹ˆë‹¤ ! ëŒ€í™” í† í° ë²„í¼ ë©”ëª¨ë¦¬(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\", 'score': 0.5996498, 'raw_content': '<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· - WikiDocs\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· CH01 LangChain ì‹œì‘í•˜ê¸° 01. ì„¤ì¹˜ ì˜ìƒë³´ê³  ë”°ë¼í•˜ê¸° 02. OpenAI API í‚¤ ë°œê¸‰ ë° í…ŒìŠ¤íŠ¸ 03. LangSmith ì¶”ì  ì„¤ì • 04. OpenAI API ì‚¬ìš©(GPT-4o ë©€í‹°ëª¨ë‹¬) 05. LangChain Expression Language(LCEL) 06. LCEL ì¸í„°í˜ì´ìŠ¤ 07. Runnable CH02 í”„ë¡¬í”„íŠ¸(Prompt) 01. í”„ë¡¬í”„íŠ¸(Prompt) 02. í“¨ìƒ· í”„ë¡¬í”„íŠ¸(FewShotPromptTemplate) 03. LangChain Hub 04. ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸(Hubì— ì—…ë¡œë“œ) CH03 ì¶œë ¥ íŒŒì„œ(Output Parsers) 01. Pydantic ì¶œë ¥ íŒŒì„œ(PydanticOutputParser) 02. ì½¤ë§ˆ êµ¬ë¶„ì ì¶œë ¥ íŒŒì„œ(CommaSeparatedListOutputParser) 03. êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ(StructuredOuputParser) 04. JSON ì¶œë ¥ íŒŒì„œ(JsonOutputParser) 05. ë°ì´í„°í”„ë ˆì„ ì¶œë ¥ íŒŒì„œ(PandasDataFrameOutputParser) 06. ë‚ ì§œ í˜•ì‹ ì¶œë ¥ íŒŒì„œ(DatetimeOutputParser) 07. ì—´ê±°í˜• ì¶œë ¥ íŒŒì„œ(EnumOutputParser) 08. ì¶œë ¥ ìˆ˜ì • íŒŒì„œ(OutputFixingParser) CH04 ëª¨ë¸(Model) 01. ë‹¤ì–‘í•œ LLM ëª¨ë¸ í™œìš© 02. ìºì‹±(Cache) 03. ëª¨ë¸ ì§ë ¬í™”(Serialization) - ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° 04. í† í° ì‚¬ìš©ëŸ‰ í™•ì¸ 05. êµ¬ê¸€ ìƒì„± AI(Google Generative AI) 06. í—ˆê¹…í˜ì´ìŠ¤ ì—”ë“œí¬ì¸íŠ¸(HuggingFace Endpoints) 07. í—ˆê¹…í˜ì´ìŠ¤ ë¡œì»¬(HuggingFace Local) 08. í—ˆê¹…í˜ì´ìŠ¤ íŒŒì´í”„ë¼ì¸(HuggingFace Pipeline) 09. ì˜¬ë¼ë§ˆ(Ollama) 10. GPT4ALL 11. ë¹„ë””ì˜¤(Video) ì§ˆì˜ ì‘ë‹µ LLM (Gemini) CH05 ë©”ëª¨ë¦¬(Memory) 01. ëŒ€í™” ë²„í¼ ë©”ëª¨ë¦¬(ConversationBufferMemory) 02. ëŒ€í™” ë²„í¼ ìœˆë„ìš° ë©”ëª¨ë¦¬(ConversationBufferWindowMemory) 03. ëŒ€í™” í† í° ë²„í¼ ë©”ëª¨ë¦¬(ConversationTokenBufferMemory) 04. ëŒ€í™” ì—”í‹°í‹° ë©”ëª¨ë¦¬(ConversationEntityMemory) 05. ëŒ€í™” ì§€ì‹ê·¸ë˜í”„ ë©”ëª¨ë¦¬(ConversationKGMemory) 06. ëŒ€í™” ìš”ì•½ ë©”ëª¨ë¦¬(ConversationSummaryMemory) 07. ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ ë©”ëª¨ë¦¬(VectorStoreRetrieverMemory) 08. LCEL Chain ì— ë©”ëª¨ë¦¬ ì¶”ê°€ 09. SQLite ì— ëŒ€í™”ë‚´ìš© ì €ì¥ 10. RunnableWithMessageHistoryì— ChatMessageHistoryì¶”ê°€ CH06 ë¬¸ì„œ ë¡œë”(Document Loader) 01. ë„íë¨¼íŠ¸(Document) ì˜ êµ¬ì¡° 02. PDF 03. í•œê¸€(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. ì›¹ ë¬¸ì„œ(WebBaseLoader) 09. í…ìŠ¤íŠ¸(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 í…ìŠ¤íŠ¸ ë¶„í• (Text Splitter) 01. ë¬¸ì í…ìŠ¤íŠ¸ ë¶„í• (CharacterTextSplitter) 02. ì¬ê·€ì  ë¬¸ì í…ìŠ¤íŠ¸ ë¶„í• (RecursiveCharacterTextSplitter) 03. í† í° í…ìŠ¤íŠ¸ ë¶„í• (TokenTextSplitter) 04. ì‹œë©˜í‹± ì²­ì»¤(SemanticChunker) 05. ì½”ë“œ ë¶„í• (Python, Markdown, JAVA, C++, C#, GO, JS, Latex ë“±) 06. ë§ˆí¬ë‹¤ìš´ í—¤ë” í…ìŠ¤íŠ¸ ë¶„í• (MarkdownHeaderTextSplitter) 07. HTML í—¤ë” í…ìŠ¤íŠ¸ ë¶„í• (HTMLHeaderTextSplitter) 08. ì¬ê·€ì  JSON ë¶„í• (RecursiveJsonSplitter) CH08 ì„ë² ë”©(Embedding) 01. OpenAIEmbeddings 02. ìºì‹œ ì„ë² ë”©(CacheBackedEmbeddings) 03. í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”©(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL ì„ë² ë”© 07. Llama CPP ì„ë² ë”© CH09 ë²¡í„°ì €ì¥ì†Œ(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 ê²€ìƒ‰ê¸°(Retriever) 01. ë²¡í„°ìŠ¤í† ì–´ ê¸°ë°˜ ê²€ìƒ‰ê¸°(VectorStore-backed Retriever) 02. ë¬¸ë§¥ ì••ì¶• ê²€ìƒ‰ê¸°(ContextualCompressionRetriever) 03. ì•™ìƒë¸” ê²€ìƒ‰ê¸°(EnsembleRetriever) 04. ê¸´ ë¬¸ë§¥ ì¬ì •ë ¬(LongContextReorder) 05. ìƒìœ„ ë¬¸ì„œ ê²€ìƒ‰ê¸°(ParentDocumentRetriever) 06. ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ê¸°(MultiQueryRetriever) 07. ë‹¤ì¤‘ ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ê¸°(MultiVectorRetriever) 08. ì…€í”„ ì¿¼ë¦¬ ê²€ìƒ‰ê¸°(SelfQueryRetriever) 09. ì‹œê°„ ê°€ì¤‘ ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ê¸°(TimeWeightedVectorStoreRetriever) 10. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° 11. Convex Combination(CC) ì ìš©ëœ ì•™ìƒë¸” ê²€ìƒ‰ê¸°(EnsembleRetriever) CH11 ë¦¬ë­ì»¤(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF ë¬¸ì„œ ê¸°ë°˜ QA(Question-Answer) 02. ë„¤ì´ë²„ ë‰´ìŠ¤ê¸°ì‚¬ QA(Question-Answer) 03. RAG ì˜ ê¸°ëŠ¥ë³„ ë‹¤ì–‘í•œ ëª¨ë“ˆ í™œìš©ê¸° 04. RAPTOR: ê¸´ ë¬¸ë§¥ ìš”ì•½(Long Context Summary) 05. ëŒ€í™”ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ” RAG ì²´ì¸ CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable êµ¬ì¡°(ê·¸ë˜í”„) ê²€í†  03. RunnableLambda 04. LLM ì²´ì¸ ë¼ìš°íŒ…(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. ë™ì  ì†ì„± ì§€ì •(configurable_fields, configurable_alternatives) 07. @chain ë°ì½”ë ˆì´í„°ë¡œ Runnable êµ¬ì„± 08. RunnableWithMessageHistory 09. ì‚¬ìš©ì ì •ì˜ ì œë„¤ë ˆì´í„°(generator) 10. Runtime Arguments ë°”ì¸ë”© 11. í´ë°±(fallback) ëª¨ë¸ ì§€ì • CH14 ì²´ì¸(Chains) 01. ë¬¸ì„œ ìš”ì•½ 02. SQL 03. êµ¬ì¡°í™”ëœ ì¶œë ¥ ì²´ì¸(with_structered_output) CH15 í‰ê°€(Evaluations) 01. í•©ì„± í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±(RAGAS) 02. RAGAS ë¥¼ í™œìš©í•œ í‰ê°€ 03. ìƒì„±í•œ í‰ê°€ìš© ë°ì´í„°ì…‹ ì—…ë¡œë“œ(HuggingFace Dataset) 04. LangSmith ë°ì´í„°ì…‹ ìƒì„± 05. LLM-as-Judge 06. ì„ë² ë”© ê¸°ë°˜ í‰ê°€(embedding_distance) 07. ì‚¬ìš©ì ì •ì˜(Custom) LLM í‰ê°€ 08. Rouge, BLEU, METEOR, SemScore ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± í‰ê°€ 09. ì‹¤í—˜(Experiment) í‰ê°€ ë¹„êµ 10. ìš”ì•½(Summary) ë°©ì‹ì˜ í‰ê°€ 11. Groundedness(í• ë£¨ì‹œë„¤ì´ì…˜) í‰ê°€ 12. ì‹¤í—˜ ë¹„êµ(Pairwise Evaluation) 13. ë°˜ë³µ í‰ê°€ 14. ì˜¨ë¼ì¸ í‰ê°€ë¥¼ í™œìš©í•œ í‰ê°€ ìë™í™” CH16 ì—ì´ì „íŠ¸(Agent) 01. ë„êµ¬(Tools) 02. ë„êµ¬ ë°”ì¸ë”©(Binding Tools) 03. ì—ì´ì „íŠ¸(Agent) 04. Claude, Gemini, Ollama, Together.ai ë¥¼ í™œìš©í•œ Agent 05. Iteration ê¸°ëŠ¥ê³¼ ì‚¬ëŒ ê°œì…(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel ë°ì´í„° ë¶„ì„ Agent 08. Toolkits í™œìš© Agent 09. RAG + Image Generator Agent(ë³´ê³ ì„œ ì‘ì„±) 10. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with Tools) CH17 LangGraph 01. í•µì‹¬ ê¸°ëŠ¥ 01. LangGraph ì— ìì£¼ ë“±ì¥í•˜ëŠ” Python ë¬¸ë²•ì´í•´ 02. LangGraphë¥¼ í™œìš©í•œ ì±—ë´‡ êµ¬ì¶• 03. LangGraphë¥¼ í™œìš©í•œ Agent êµ¬ì¶• 04. Agent ì— ë©”ëª¨ë¦¬(memory) ì¶”ê°€ 05. ë…¸ë“œì˜ ë‹¨ê³„ë³„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ 06. Human-in-the-loop(ì‚¬ëŒì˜ ê°œì…) 07. ì¤‘ê°„ë‹¨ê³„ ê°œì… ë˜ëŒë¦¼ì„ í†µí•œ ìƒíƒœ ìˆ˜ì •ê³¼ Replay 08. ì‚¬ëŒ(Human)ì—ê²Œ ë¬¼ì–´ë³´ëŠ” ë…¸ë“œ ì¶”ê°€ 09. ë©”ì‹œì§€ ì‚­ì œ(RemoveMessage) 10. ToolNode ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ë°©ë²• 11. ë³‘ë ¬ ë…¸ë“œ ì‹¤í–‰ì„ ìœ„í•œ ë¶„ê¸° ìƒì„± ë°©ë²• 12. ëŒ€í™” ê¸°ë¡ ìš”ì•½ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²• 13. ì„œë¸Œê·¸ë˜í”„ ì¶”ê°€ ë° ì‚¬ìš© ë°©ë²• 14. ì„œë¸Œê·¸ë˜í”„ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ë³€í™˜í•˜ëŠ” ë°©ë²• 15. LangGraph ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì˜ ëª¨ë“  ê²ƒ 02. êµ¬ì¡° ì„¤ê³„ 01. ê¸°ë³¸ ê·¸ë˜í”„ ìƒì„± 02. Naive RAG 03. ê´€ë ¨ì„± ì²´ì»¤(Relevance Checker) ëª¨ë“ˆ ì¶”ê°€ 04. ì›¹ ê²€ìƒ‰ ëª¨ë“ˆ ì¶”ê°€ 05. ì¿¼ë¦¬ ì¬ì‘ì„± ëª¨ë“ˆ ì¶”ê°€ 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. ì—ì´ì „íŠ¸ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜ (ê³ ê° ì‘ëŒ€ ì‹œë‚˜ë¦¬ì˜¤) 02. ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ë©”íƒ€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì—ì´ì „íŠ¸ 03. CRAG(Corrective RAG) 04. Self-RAG 05. ê³„íš í›„ ì‹¤í–‰(Plan-and-Execute) 06. ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—… ë„¤íŠ¸ì›Œí¬(Multi-Agent Collaboration Network) 07. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) 08. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) 09. SQL ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ 10. STORM ê°œë…ì„ ë„ì…í•œ ì—°êµ¬ë¥¼ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ CH18 ê¸°íƒ€ ì •ë³´ 01. StreamEvent íƒ€ì…ë³„ ì •ë¦¬\\nPublished with WikiDocs\\n\\n\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - Langâ€¦\\n\\n\\në„ì„œ ì¦ì • ì´ë²¤íŠ¸ !!\\n\\nWikiDocs\\n\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡·\\n\\nAuthor: í…Œë””ë…¸íŠ¸\\nLast edited by : Jan. 16, 2025, 12:23 a.m.\\nCopyright : \\n2,553 Like; \"ì¶”ì²œ\")\\nì¶”ì²œì€ ê³µìœ í•  ìˆ˜ ìˆëŠ” ë¬´ë£Œ ì „ìì±…ì„ ì§‘í•„í•˜ëŠ”ë° ì •ë§ í° í˜ì´ ë©ë‹ˆë‹¤. \"ì¶”ì²œ\" í•œ ë²ˆì”©ë§Œ ë¶€íƒ ë“œë¦¬ê² ìŠµë‹ˆë‹¤ğŸ™ğŸ™\\nâœ… ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ê°•ì˜\\níŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ - RAG ë¹„ë²•ë…¸íŠ¸\\nâœ… ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ì½”ë“œì €ì¥ì†Œ(GitHub) ğŸ“˜ğŸ–¥ï¸\\nhttps://github.com/teddylee777/langchain-kr\\nâœ… ìœ íŠœë¸Œ \"í…Œë””ë…¸íŠ¸\" ğŸ¥ğŸ“š\\nhttps://www.youtube.com/c/@teddynote\\nâœ… ë°ì´í„° ë¶„ì„ ë¸”ë¡œê·¸ https://teddylee777.github.io\\nâœ… ë¬¸ì˜ teddylee777@gmail.com\\nLICENSE\\nì¸ìš© ë° ì¶œì²˜ í‘œê¸°\\n\\në³¸ ì €ì‘ë¬¼ì„ ë¸”ë¡œê·¸, ìœ íŠœë¸Œ ë“± ì˜¨ë¼ì¸ ë§¤ì²´ì— ì¸ìš©í•˜ì—¬ ê²Œì¬í•  ê²½ìš°, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea ë¼ì´ì„ ìŠ¤ì— ë”°ë¼ ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\\n\\nìƒì—…ì  ì‚¬ìš©ì— ëŒ€í•œ ì‚¬ì „ í˜‘ì˜\\n\\në³¸ ì €ì‘ë¬¼(Wikidocs ë° ê´€ë ¨ ì‹¤ìŠµ ì½”ë“œ í¬í•¨)ì„ ê°•ì˜, ê°•ì—° ë“± ìƒì—…ì  ëª©ì ìœ¼ë¡œ í™œìš©í•˜ê³ ì í•˜ëŠ” ê²½ìš°, ì €ì‘ê¶Œìì™€ì˜ ì‚¬ì „ ì„œë©´ í˜‘ì˜ê°€ í•„ìˆ˜ì ìœ¼ë¡œ ìš”êµ¬ë©ë‹ˆë‹¤. í•´ë‹¹ í˜‘ì˜ëŠ” teddylee777@gmail.comìœ¼ë¡œ ë¬¸ì˜í•˜ì—¬ ì§„í–‰í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në³¸ ì €ì‘ë¬¼ì€ 2024ë…„ í…Œë””ë…¸íŠ¸ì— ì˜í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. \\nëª¨ë“  ê¶Œë¦¬ëŠ” ì €ì‘ê¶Œìì—ê²Œ ìˆìœ¼ë©°, ë³¸ ì €ì‘ë¬¼ì€ Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea ë¼ì´ì„ ìŠ¤ì— ë”°ë¼ ë°°í¬ë©ë‹ˆë‹¤.\\në³¸ ì €ì‘ë¬¼ì˜ ë¬´ë‹¨ ì „ì¬ ë° ì¬ë°°í¬ë¥¼ ê¸ˆì§€í•˜ë©°, ì „ì²´ í˜¹ì€ ì¼ë¶€ë¥¼ ì¸ìš©í•  ê²½ìš° ì¶œì²˜ë¥¼ ëª…í™•íˆ ë°í˜€ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\\në³¸ ë¬¸ì„œëŠ” ë‹¤ë¥¸ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³  ìë£ŒëŠ” ë³¸ ë¬¸ì„œ í•˜ë‹¨ì˜ ì¶œì²˜ ëª©ë¡ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nCopyright (c) í…Œë””ë…¸íŠ¸.\\nReference\\n\\nLangChain Github\\nLangGraph Github\\nLangChain Document\\n\\nRecent Comments (8) Recent Modifications (10) RSS\\n02. ë„¤ì´ë²„ ë‰´ìŠ¤ê¸°ì‚¬ QA(Question-Answer) - ê¹€ë¯¼ê²¸, Feb. 2, 2025, 12:17 p.m.\\n\"bullet points í˜•ì‹ìœ¼ë¡œ ì •ë¦¬\"ì—ì„œ \"ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\" ë¼ê³  ë‚˜ì˜¤ëŠ”ë° ì´ìœ ë¥¼ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? kmk582@naver.com\\n10. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m.\\nì¶œë ¥ëœ ê²°ê³¼ë¥¼ ë¹„êµí–ˆì„ ë•Œ, kiwi tokenizerì„ ì‚¬ìš©í•œ ê²°ê³¼ì™€ kkma, okt ë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ê°€ í° ì°¨ì´ê°€ ì—†ë‹¤ê³  ë´ë„ ë˜ëŠ” ê±´ê°€ìš”?\\nCH01 LangChain ì‹œì‘í•˜ê¸° - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\nì¢‹ì€ ìë£Œë¥¼ ë¬´ë£Œë¡œ ê³µìœ í•´ ì£¼ì…”ì„œ, ê°ì‚¬í•œ ë§ˆìŒì— \\'í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸\\' ê°•ì˜ ë“±ë¡í–ˆìŠµë‹ˆë‹¤ ! ë¬¼ë¡  ì œ í˜„ì—…ì— í•„ìš”í•œ ê¸°ìˆ ì´ë¼ì„œ, ê°•ì˜ ë˜í•œ ê¸°ìœ ë§ˆìŒì— ì‹ ì²­í–ˆêµ¬ìš” ~ ì •ì£¼í–‰ í•´ì„œ, ì°½ê³µì„ ë‚ ì•„ê°€ ë³´ê² ìŠµë‹ˆë‹¤ ^^\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\npython-docxë„ ì„¤ì¹˜í•´ì•¼ í• ê¹Œìš”?\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\n!pip install jq ë¶€ë¶„ì´ ë“¤ì–´ê°€ì•¼ í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤.\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\n<html><head> <meta http-equiv=\"Content-Type\" content=\"text/html\"> </head><body> <span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span> <div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div> <div style=\"position:absolute; border ì´ ë¶€ë¶„ì´ ì¶œë ¥ ê²°ê³¼ê°€ ì•„ë‹ˆë¼ ì½”ë“œì¸ ê²ƒì²˜ëŸ¼ í‘œì‹œë˜ì–´ ìˆë„¤ìš”~\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\nê°ì‚¬íˆ ì˜ ì°¸ê³ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„ì£¼ ì‚¬ì†Œí•œ ì˜¤ê¸°ì´ì§€ë§Œ... 11ë²ˆ Arxiv ë‹¤ìŒì— 12ë²ˆì´ ì™€ì•¼ í•  í…ë°, ì›ë˜ ë„£ìœ¼ì‹œë ¤ë˜ ë‹¤ë¥¸ ëª©ì°¨ê°€ ë¹ ì§„ ê²ƒì¸ì§€ ë°”ë¡œ 13ë²ˆì´ ë‚˜ì™”ë„¤ìš”^^\\n03. ëª¨ë¸ ì§ë ¬í™”(Serialization) - ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° - ë™êµ¬, Sept. 20, 2024, 12:58 p.m.\\nloadsëŠ” ë­ì—ìš”?\\n10. JSON - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n03. ëŒ€í™” í† í° ë²„í¼ ë©”ëª¨ë¦¬(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n05. ì½”ë“œ ë¶„í• (Python, Markdown, JAVA, C++, C#, GO, JS, Latex ë“±) - Jan. 16, 2025, 12:19 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n10. STORM ê°œë…ì„ ë„ì…í•œ ì—°êµ¬ë¥¼ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ - Dec. 23, 2024, 3:16 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n05. ê³„íš í›„ ì‹¤í–‰(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n07. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n08. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n09. SQL ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n\\nNext : CH01 LangChain ì‹œì‘í•˜ê¸°\\n\\n\\nÃ—\\nì±…ê°ˆí”¼\\nì¶”ê°€ ë‹«ê¸°\\n\\nÃ—\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\nâ€» Feedback is delivered to the author by email.\\nClose Send'}, {'title': 'ë­ì²´ì¸(langchain) + PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering) (8) - í…Œë””ë…¸íŠ¸', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-08/', 'content': 'â‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€ â‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ â‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ â‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ ë­ì²´ì¸(langchain) + PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering) (8) 2023ë…„ 10ì›” 13ì¼ 2 ë¶„ ì†Œìš” ëª©ì°¨ ğŸŒ± í™˜ê²½ì„¤ì • ğŸ”¥ PDF ê¸°ë°˜ ì§ˆì˜ ì‘ë‹µ(Question-Answering) â‘  ë°ì´í„° ë¡œë“œ â‘¡ ë°ì´í„° ë¶„í•  â‘¢ ì €ì¥ ë° ê²€ìƒ‰ â‘£ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ â‘¤ ìƒì„± â‘¥ í…ŒìŠ¤íŠ¸ ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ë­ì²´ì¸(LangChain) ì„ í™œìš©í•˜ì—¬ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³ , ë¬¸ì„œì˜ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ì§ˆì˜ì‘ë‹µ(Question-Answering) í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ì´ë²ˆ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” langchain ì˜ ë¬¸ì„œ ë¡œë“œ - ë¶„í•  - ë²¡í„°ìŠ¤í† ì–´(vectorstore)ì— ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥ í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. í›„ë°˜ë¶€ì—ëŠ” langchain hub ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ê³ , ì´ë¥¼ ChatGPT ëª¨ë¸ê³¼ ê²°í•©í•˜ì—¬ ë¬¸ì„œì— ê¸°ë°˜í•œ ì§ˆì˜ì‘ë‹µ Chain ì„ ìƒì„±í•©ë‹ˆë‹¤. ìƒì„±: LLMì€ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.', 'score': 0.55998856, 'raw_content': 'ë­ì²´ì¸(langchain) + PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering) (8) - í…Œë””ë…¸íŠ¸\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\ní…Œë””ë…¸íŠ¸ ë°ì´í„°ì™€ ì¸ê³µì§€ëŠ¥ì„ ì¢‹ì•„í•˜ëŠ” ê°œë°œì ë…¸íŠ¸\\n\\nê²€ìƒ‰\\nì¹´í…Œê³ ë¦¬\\níƒœê·¸\\nì—°ë„\\nê°•ì˜\\nì–´ë°”ì›ƒë¯¸\\n\\ní† ê¸€ ë©”ë‰´\\n\\nHome \\n/3.  Langchain \\n/5.  ë­ì²´ì¸(langchain) + PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering) (8)\\n\\nğŸ”¥ì•Œë¦¼ğŸ”¥\\nâ‘  í…Œë””ë…¸íŠ¸ ìœ íŠœë¸Œ - êµ¬ê²½í•˜ëŸ¬ ê°€ê¸°!\\nâ‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€\\nâ‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ\\nâ‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ\\nâ‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ\\në­ì²´ì¸(langchain) + PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering) (8)\\n2023ë…„ 10ì›” 13ì¼ 2 ë¶„ ì†Œìš”\\nëª©ì°¨\\n\\nğŸŒ± í™˜ê²½ì„¤ì •\\nğŸ”¥ PDF ê¸°ë°˜ ì§ˆì˜ ì‘ë‹µ(Question-Answering)\\nâ‘  ë°ì´í„° ë¡œë“œ\\nâ‘¡ ë°ì´í„° ë¶„í• \\nâ‘¢ ì €ì¥ ë° ê²€ìƒ‰\\nâ‘£ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\\nâ‘¤ ìƒì„±\\nâ‘¥ í…ŒìŠ¤íŠ¸\\n\\n\\n\\nì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ë­ì²´ì¸(LangChain) ì„ í™œìš©í•˜ì—¬ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³ , ë¬¸ì„œì˜ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ì§ˆì˜ì‘ë‹µ(Question-Answering) í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\\nì´ë²ˆ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” langchain ì˜ ë¬¸ì„œ ë¡œë“œ - ë¶„í•  - ë²¡í„°ìŠ¤í† ì–´(vectorstore)ì— ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥ í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì—¬ëŸ¬ ë²¡í„°ìŠ¤í† ì–´ ì¤‘ ì˜¤í”ˆì†ŒìŠ¤ì¸ Chroma DB ë¥¼ í™œìš©í•©ë‹ˆë‹¤.\\ní›„ë°˜ë¶€ì—ëŠ” langchain hub ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ê³ , ì´ë¥¼ ChatGPT ëª¨ë¸ê³¼ ê²°í•©í•˜ì—¬ ë¬¸ì„œì— ê¸°ë°˜í•œ ì§ˆì˜ì‘ë‹µ Chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n\\nâœ”ï¸ (ì´ì „ê¸€) LangChain íŠœí† ë¦¬ì–¼\\n\\në­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²•\\në­ì²´ì¸(langchain) + í—ˆê¹…í˜ì´ìŠ¤(HuggingFace) ëª¨ë¸ ì‚¬ìš©ë²•\\në­ì²´ì¸(langchain) + ì±—(chat) - ConversationChain, í…œí”Œë¦¿ ì‚¬ìš©ë²•\\në­ì²´ì¸(langchain) + ì •í˜•ë°ì´í„°(CSV, Excel) - ChatGPT ê¸°ë°˜ ë°ì´í„°ë¶„ì„\\në­ì²´ì¸(langchain) + ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ - ì›¹ì‚¬ì´íŠ¸ ë¬¸ì„œ ìš”ì•½\\në­ì²´ì¸(langchain) + ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ì¶”ì¶œ - ìŠ¤í‚¤ë§ˆ í™œìš©ë²•\\në­ì²´ì¸(langchain) + PDF ë¬¸ì„œìš”ì•½, Map-Reduce\\n\\n\\nğŸŒ± í™˜ê²½ì„¤ì •\\n```\\ní•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\\n!pip install -q openai langchain langchainhub pypdf\\n```\\n```\\nOPENAI_API\\nimport os\\nos.environ[\\'OPENAI_API_KEY\\'] = \\'OPENAI API KEY ì…ë ¥\\'\\n```\\n```\\ní† í° ì •ë³´ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\\nì„¤ì¹˜: pip install python-dotenv\\nfrom dotenv import load_dotenv\\ní† í° ì •ë³´ë¡œë“œ\\nload_dotenv()\\n```\\nTrue\\nğŸ”¥ PDF ê¸°ë°˜ ì§ˆì˜ ì‘ë‹µ(Question-Answering)\\n\\në‹¤ìŒì€ ë¹„êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ QA ì²´ì¸(Question-Answering chain) ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì— ëŒ€í•œ ê¸°ìˆ ì  ë²ˆì—­ì…ë‹ˆë‹¤:\\n\\n\\në°ì´í„° ë¡œë“œ: ìš°ì„ , ë°ì´í„°ë¥¼ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤. LangChain í†µí•© í—ˆë¸Œë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ë¡œë” ì„¸íŠ¸ë¥¼ ë‘˜ëŸ¬ë³´ì„¸ìš”.\\n\\n\\në°ì´í„° ë¶„í• : í…ìŠ¤íŠ¸ ë¶„í• ê¸°ëŠ” ë¬¸ì„œë¥¼ ì§€ì •ëœ í¬ê¸°ì˜ ë¶„í• ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\\n\\n\\nì €ì¥: ì €ì¥ì†Œ(ì˜ˆ: ì¢…ì¢… vectorstore)ëŠ” ë¶„í• ì„ ë³´ê´€í•˜ê³  ì¢…ì¢… ì„ë² ë“œí•©ë‹ˆë‹¤.\\n\\n\\nê²€ìƒ‰: ì•±ì€ ì €ì¥ì†Œì—ì„œ ë¶„í• ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤(ì˜ˆ: ì¢…ì¢… ì…ë ¥ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ì„ë² ë”©ìœ¼ë¡œ).\\n\\n\\nìƒì„±: LLMì€ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n\\n\\nâ‘  ë°ì´í„° ë¡œë“œ\\nPyPDFLoader ë¥¼ í™œìš©í•˜ì—¬ PDF íŒŒì¼ì„ ë¡œë“œ í•©ë‹ˆë‹¤.\\n```\\nfrom langchain.document_loaders import PyPDFLoader\\nPDF íŒŒì¼ ë¡œë“œ\\nloader = PyPDFLoader(\"data/í™©ìˆœì›-ì†Œë‚˜ê¸°.pdf\")\\ndocument = loader.load()\\ndocument[0].page_content[:200] # ë‚´ìš© ì¶”ì¶œ\\n```\\n\\'- 1 -ì†Œë‚˜ê¸°\\\\ní™©ìˆœì›\\\\nì†Œë…„ì€ ê°œìš¸ê°€ì—ì„œ ì†Œë…€ë¥¼ ë³´ì ê³§ ìœ¤ ì´ˆì‹œë„¤ ì¦ì†ë…€ (æ›¾å­«å¥³ )ë”¸ì´ë¼ëŠ” ê±¸ ì•Œ ìˆ˜ ìˆì—ˆë‹¤ . \\\\nì†Œë…€ëŠ” ê°œìš¸ì—ë‹¤ ì†ì„ ì ê·¸ê³  ë¬¼ì¥ë‚œì„ í•˜ê³  ìˆëŠ” ê²ƒì´ë‹¤ . ì„œìš¸ì„œëŠ” ì´ëŸ° ê°œìš¸ë¬¼ì„ ë³´ì§€ \\\\nëª»í•˜ê¸°ë‚˜ í•œ ë“¯ì´.\\\\në²Œì¨ ë©°ì¹ ì§¸ ì†Œë…€ëŠ” , í•™êµì—ì„œ ëŒì•„ì˜¤ëŠ” ê¸¸ì— ë¬¼ì¥ë‚œì´ì—ˆë‹¤ . ê·¸ëŸ°ë° , ì–´ì œê¹Œì§€ ê°œìš¸ ê¸°ìŠ­ì—\\\\nì„œ í•˜ë”ë‹ˆ , ì˜¤ëŠ˜ì€ ì§•ê²€ë‹¤ë¦¬ í•œê°€ìš´\\'\\nâ‘¡ ë°ì´í„° ë¶„í• \\nCharacterTextSplitter ë¡œ chunk_size ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œë¥¼ ìª¼ê°­ë‹ˆë‹¤. chunk_overlap ì— 50ê°œì˜ í† í°ì„ ì§€ì •í•˜ì—¬ ë¬¸ì„œ-ë¬¸ì„œ ê°„ ê²¹ì³ì§€ëŠ” ë¶€ë¶„(overlap) ì´ ìˆë„ë¡ í•˜ì—¬ ë¹„êµì  ìœ ì—°í•œ ìš”ì•½ ê²°ê³¼ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\\n```\\nfrom langchain.text_splitter import CharacterTextSplitter\\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\\ntexts = text_splitter.split_documents(document)\\n```\\nâ‘¢ ì €ì¥ ë° ê²€ìƒ‰\\nOpenAIEmbeddings ë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì„ë² ë”©í•œ ë’¤, Chroma ë²¡í„°ìŠ¤í† ì–´(vectorstore) ì— ì €ì¥í•©ë‹ˆë‹¤.\\në§ˆì§€ë§‰ ì¤„ì—ëŠ” as_retriever() ë¡œ retriever í˜•íƒœë¡œ ê°€ì ¸ì˜¤ëŠ”ë°, ì´ëŠ” ì¶”í›„ ì‚¬ìš©ìì˜ query ì…ë ¥ì‹œ, ì…ë ¥ëœ queryë¡œ vectorestoreì—ì„œ ìœ ì‚¬ì„±ì´ ë†’ì€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ ë‚¼ ë•Œ ì“°ì…ë‹ˆë‹¤.\\n```\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom langchain.vectorstores import Chroma\\nì„ë² ë”©\\nembeddings = OpenAIEmbeddings()\\nChroma DB ì— ì €ì¥\\ndocsearch = Chroma.from_documents(texts, embeddings)\\nretriever ê°€ì ¸ì˜´\\nretriever = docsearch.as_retriever()\\n```\\nâ‘£ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\\nì•„ë˜ì˜ ì˜ˆì œëŠ” langchain hub ì—ì„œ RAG Prompt ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.\\nì´ì²˜ëŸ¼ langchain hub ì—ì„œ ê³µê°œëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ê±°ë‚˜, ChatPromptTemplate ë¥¼ ì§ì ‘ ìƒì„±í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. ìì„¸í•œ ì‚¬í•­ì€ ConversationChain, í…œí”Œë¦¿ ì‚¬ìš©ë²• ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n```\\nlangchain hub ì—ì„œ Prompt ë‹¤ìš´ë¡œë“œ ì˜ˆì‹œ\\nhttps://smith.langchain.com/hub/rlm/rag-prompt\\nfrom langchain import hub\\nrag_prompt = hub.pull(\"rlm/rag-prompt\")\\nrag_prompt\\n```\\nChatPromptTemplate(input_variables=[\\'question\\', \\'context\\'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\\'question\\', \\'context\\'], output_parser=None, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\\\nQuestion: {question} \\\\nContext: {context} \\\\nAnswer:\", template_format=\\'f-string\\', validate_template=True), additional_kwargs={})])\\nâ‘¤ ìƒì„±\\në§ˆì§€ë§‰ ë‹¨ê³„ëŠ” LLM ëª¨ë¸ì„ ì •ì˜í•˜ê³  Chain ì„ ìƒì„±í•˜ëŠ” ë‹¨ê³„ ì…ë‹ˆë‹¤.\\n```\\nLLM\\nfrom langchain.chat_models import ChatOpenAI\\nChatGPT ëª¨ë¸ ì§€ì •\\nllm = ChatOpenAI(model_name=\"gpt-4-0613\", temperature=0)\\n```\\n```\\nRAG chain ìƒì„±\\nfrom langchain.schema.runnable import RunnablePassthrough\\npipe operatorë¥¼ í™œìš©í•œ ì²´ì¸ ìƒì„±\\nrag_chain = (\\n    {\"context\": retriever, \"question\": RunnablePassthrough()} \\n    | rag_prompt \\n    | llm \\n)\\n```\\nâ‘¥ í…ŒìŠ¤íŠ¸\\nrag_chain.invoke(\"ì´ ì†Œì„¤ì˜ ì œëª©ì€ ë­ì•¼?\")\\nAIMessage(content=\\'ì´ ì†Œì„¤ì˜ ì œëª©ì€ \"ì†Œë‚˜ê¸°\"ì…ë‹ˆë‹¤.\\', additional_kwargs={}, example=False)\\nrag_chain.invoke(\"ì´ ì†Œì„¤ì˜ ì €ìëŠ” ëˆ„êµ¬ì•¼?\")\\nAIMessage(content=\\'ì´ ì†Œì„¤ì˜ ì €ìëŠ” í™©ìˆœì›ì…ë‹ˆë‹¤.\\', additional_kwargs={}, example=False)\\níƒœê·¸: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, PDF, ë­ì²´ì¸, ë­ì²´ì¸ íŠœí† ë¦¬ì–¼, ë¬¸ì„œìš”ì•½, ì§ˆì˜ì‘ë‹µ, í¬ë¡¤ë§\\nì¹´í…Œê³ ë¦¬: langchain\\nì—…ë°ì´íŠ¸: 2023ë…„ 10ì›” 13ì¼\\nê³µìœ í•˜ê¸°\\nTwitter Facebook LinkedIn\\nì´ì „ ë‹¤ìŒ\\nëŒ“ê¸€ë‚¨ê¸°ê¸°\\nì°¸ê³ \\npoetry ì˜ ê±°ì˜ ëª¨ë“ ê²ƒ (íŠœí† ë¦¬ì–¼)\\n2024ë…„ 03ì›” 30ì¼ 5 ë¶„ ì†Œìš”\\nPython ê°œë°œì— ìˆì–´ì„œ poetryëŠ” ë§¤ìš° ê°•ë ¥í•œ ë„êµ¬ë¡œ, í”„ë¡œì íŠ¸ì˜ ì˜ì¡´ì„± ê´€ë¦¬ì™€ íŒ¨í‚¤ì§€ ë°°í¬ë¥¼ ê°„ì†Œí™”í•˜ëŠ” ë° í° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° poetry í™œìš© íŠœí† ë¦¬ì–¼ì„ ì‚´í´ ë³´ê² ìŠµë‹ˆë‹¤.\\nLangGraph Retrieval Agentë¥¼ í™œìš©í•œ ë™ì  ë¬¸ì„œ ê²€ìƒ‰ ë° ì²˜ë¦¬\\n2024ë…„ 03ì›” 06ì¼ 10 ë¶„ ì†Œìš”\\nLangGraph Retrieval AgentëŠ” ì–¸ì–´ ì²˜ë¦¬, AI ëª¨ë¸ í†µí•©, ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬, ê·¸ë˜í”„ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì–¸ì–´ ê¸°ë°˜ AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— í•„ìˆ˜ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤.\\n[Assistants API] Code Interpreter, Retrieval, Functions í™œìš©ë²•\\n2024ë…„ 02ì›” 13ì¼ 35 ë¶„ ì†Œìš”\\nOpenAIì˜ ìƒˆë¡œìš´ Assistants APIëŠ” ëŒ€í™”ì™€ ë”ë¶ˆì–´ ê°•ë ¥í•œ ë„êµ¬ ì ‘ê·¼ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì€ OpenAI Assistants APIë¥¼ í™œìš©í•˜ëŠ” ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤. íŠ¹íˆ, Assistant API ê°€ ì œê³µí•˜ëŠ” ë„êµ¬ì¸ Code Interpreter, Retrieval...\\n[LangChain] ì—ì´ì „íŠ¸(Agent)ì™€ ë„êµ¬(tools)ë¥¼ í™œìš©í•œ ì§€ëŠ¥í˜• ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ\\n2024ë…„ 02ì›” 09ì¼ 41 ë¶„ ì†Œìš”\\nì´ ê¸€ì—ì„œëŠ” LangChain ì˜ Agent í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ê²€ìƒ‰ê³¼ ë°ì´í„° ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. LangSmith ë¥¼ ì‚¬ìš©í•˜ì—¬ Agentì˜ ì¶”ë¡  ë‹¨ê³„ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. Agentê°€ í™œìš©í•  ê²€ìƒ‰ ë„êµ¬(Tavily Search), PDF ê¸°ë°˜ ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„...\\n\\níŒ”ë¡œìš°:\\nYouTube\\nGitHub\\nInstagram\\ní”¼ë“œ\\n\\nÂ© 2024 í…Œë””ë…¸íŠ¸. Powered by Jekyll & Minimal Mistakes.'}, {'title': 'ë­ì²´ì¸(langchain) + PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering) (8) - í…Œë””ë…¸íŠ¸', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-08/', 'content': 'â‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€ â‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ â‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ â‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ ë­ì²´ì¸(langchain) + PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering) (8) 2023ë…„ 10ì›” 13ì¼ 2 ë¶„ ì†Œìš” ëª©ì°¨ ğŸŒ± í™˜ê²½ì„¤ì • ğŸ”¥ PDF ê¸°ë°˜ ì§ˆì˜ ì‘ë‹µ(Question-Answering) â‘  ë°ì´í„° ë¡œë“œ â‘¡ ë°ì´í„° ë¶„í•  â‘¢ ì €ì¥ ë° ê²€ìƒ‰ â‘£ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ â‘¤ ìƒì„± â‘¥ í…ŒìŠ¤íŠ¸ ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ë­ì²´ì¸(LangChain) ì„ í™œìš©í•˜ì—¬ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³ , ë¬¸ì„œì˜ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ì§ˆì˜ì‘ë‹µ(Question-Answering) í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ì´ë²ˆ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” langchain ì˜ ë¬¸ì„œ ë¡œë“œ - ë¶„í•  - ë²¡í„°ìŠ¤í† ì–´(vectorstore)ì— ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥ í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. í›„ë°˜ë¶€ì—ëŠ” langchain hub ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ê³ , ì´ë¥¼ ChatGPT ëª¨ë¸ê³¼ ê²°í•©í•˜ì—¬ ë¬¸ì„œì— ê¸°ë°˜í•œ ì§ˆì˜ì‘ë‹µ Chain ì„ ìƒì„±í•©ë‹ˆë‹¤. ìƒì„±: LLMì€ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.', 'score': 0.55998856, 'raw_content': 'ë­ì²´ì¸(langchain) + PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering) (8) - í…Œë””ë…¸íŠ¸\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\ní…Œë””ë…¸íŠ¸ ë°ì´í„°ì™€ ì¸ê³µì§€ëŠ¥ì„ ì¢‹ì•„í•˜ëŠ” ê°œë°œì ë…¸íŠ¸\\n\\nê²€ìƒ‰\\nì¹´í…Œê³ ë¦¬\\níƒœê·¸\\nì—°ë„\\nê°•ì˜\\nì–´ë°”ì›ƒë¯¸\\n\\ní† ê¸€ ë©”ë‰´\\n\\nHome \\n/3.  Langchain \\n/5.  ë­ì²´ì¸(langchain) + PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering) (8)\\n\\nğŸ”¥ì•Œë¦¼ğŸ”¥\\nâ‘  í…Œë””ë…¸íŠ¸ ìœ íŠœë¸Œ - êµ¬ê²½í•˜ëŸ¬ ê°€ê¸°!\\nâ‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€\\nâ‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ\\nâ‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ\\nâ‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ\\në­ì²´ì¸(langchain) + PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering) (8)\\n2023ë…„ 10ì›” 13ì¼ 2 ë¶„ ì†Œìš”\\nëª©ì°¨\\n\\nğŸŒ± í™˜ê²½ì„¤ì •\\nğŸ”¥ PDF ê¸°ë°˜ ì§ˆì˜ ì‘ë‹µ(Question-Answering)\\nâ‘  ë°ì´í„° ë¡œë“œ\\nâ‘¡ ë°ì´í„° ë¶„í• \\nâ‘¢ ì €ì¥ ë° ê²€ìƒ‰\\nâ‘£ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\\nâ‘¤ ìƒì„±\\nâ‘¥ í…ŒìŠ¤íŠ¸\\n\\n\\n\\nì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ë­ì²´ì¸(LangChain) ì„ í™œìš©í•˜ì—¬ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³ , ë¬¸ì„œì˜ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ì§ˆì˜ì‘ë‹µ(Question-Answering) í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\\nì´ë²ˆ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” langchain ì˜ ë¬¸ì„œ ë¡œë“œ - ë¶„í•  - ë²¡í„°ìŠ¤í† ì–´(vectorstore)ì— ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥ í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì—¬ëŸ¬ ë²¡í„°ìŠ¤í† ì–´ ì¤‘ ì˜¤í”ˆì†ŒìŠ¤ì¸ Chroma DB ë¥¼ í™œìš©í•©ë‹ˆë‹¤.\\ní›„ë°˜ë¶€ì—ëŠ” langchain hub ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ê³ , ì´ë¥¼ ChatGPT ëª¨ë¸ê³¼ ê²°í•©í•˜ì—¬ ë¬¸ì„œì— ê¸°ë°˜í•œ ì§ˆì˜ì‘ë‹µ Chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n\\nâœ”ï¸ (ì´ì „ê¸€) LangChain íŠœí† ë¦¬ì–¼\\n\\në­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²•\\në­ì²´ì¸(langchain) + í—ˆê¹…í˜ì´ìŠ¤(HuggingFace) ëª¨ë¸ ì‚¬ìš©ë²•\\në­ì²´ì¸(langchain) + ì±—(chat) - ConversationChain, í…œí”Œë¦¿ ì‚¬ìš©ë²•\\në­ì²´ì¸(langchain) + ì •í˜•ë°ì´í„°(CSV, Excel) - ChatGPT ê¸°ë°˜ ë°ì´í„°ë¶„ì„\\në­ì²´ì¸(langchain) + ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ - ì›¹ì‚¬ì´íŠ¸ ë¬¸ì„œ ìš”ì•½\\në­ì²´ì¸(langchain) + ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ì¶”ì¶œ - ìŠ¤í‚¤ë§ˆ í™œìš©ë²•\\në­ì²´ì¸(langchain) + PDF ë¬¸ì„œìš”ì•½, Map-Reduce\\n\\n\\nğŸŒ± í™˜ê²½ì„¤ì •\\n```\\ní•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\\n!pip install -q openai langchain langchainhub pypdf\\n```\\n```\\nOPENAI_API\\nimport os\\nos.environ[\\'OPENAI_API_KEY\\'] = \\'OPENAI API KEY ì…ë ¥\\'\\n```\\n```\\ní† í° ì •ë³´ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\\nì„¤ì¹˜: pip install python-dotenv\\nfrom dotenv import load_dotenv\\ní† í° ì •ë³´ë¡œë“œ\\nload_dotenv()\\n```\\nTrue\\nğŸ”¥ PDF ê¸°ë°˜ ì§ˆì˜ ì‘ë‹µ(Question-Answering)\\n\\në‹¤ìŒì€ ë¹„êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ QA ì²´ì¸(Question-Answering chain) ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì— ëŒ€í•œ ê¸°ìˆ ì  ë²ˆì—­ì…ë‹ˆë‹¤:\\n\\n\\në°ì´í„° ë¡œë“œ: ìš°ì„ , ë°ì´í„°ë¥¼ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤. LangChain í†µí•© í—ˆë¸Œë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ë¡œë” ì„¸íŠ¸ë¥¼ ë‘˜ëŸ¬ë³´ì„¸ìš”.\\n\\n\\në°ì´í„° ë¶„í• : í…ìŠ¤íŠ¸ ë¶„í• ê¸°ëŠ” ë¬¸ì„œë¥¼ ì§€ì •ëœ í¬ê¸°ì˜ ë¶„í• ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\\n\\n\\nì €ì¥: ì €ì¥ì†Œ(ì˜ˆ: ì¢…ì¢… vectorstore)ëŠ” ë¶„í• ì„ ë³´ê´€í•˜ê³  ì¢…ì¢… ì„ë² ë“œí•©ë‹ˆë‹¤.\\n\\n\\nê²€ìƒ‰: ì•±ì€ ì €ì¥ì†Œì—ì„œ ë¶„í• ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤(ì˜ˆ: ì¢…ì¢… ì…ë ¥ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ì„ë² ë”©ìœ¼ë¡œ).\\n\\n\\nìƒì„±: LLMì€ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n\\n\\nâ‘  ë°ì´í„° ë¡œë“œ\\nPyPDFLoader ë¥¼ í™œìš©í•˜ì—¬ PDF íŒŒì¼ì„ ë¡œë“œ í•©ë‹ˆë‹¤.\\n```\\nfrom langchain.document_loaders import PyPDFLoader\\nPDF íŒŒì¼ ë¡œë“œ\\nloader = PyPDFLoader(\"data/í™©ìˆœì›-ì†Œë‚˜ê¸°.pdf\")\\ndocument = loader.load()\\ndocument[0].page_content[:200] # ë‚´ìš© ì¶”ì¶œ\\n```\\n\\'- 1 -ì†Œë‚˜ê¸°\\\\ní™©ìˆœì›\\\\nì†Œë…„ì€ ê°œìš¸ê°€ì—ì„œ ì†Œë…€ë¥¼ ë³´ì ê³§ ìœ¤ ì´ˆì‹œë„¤ ì¦ì†ë…€ (æ›¾å­«å¥³ )ë”¸ì´ë¼ëŠ” ê±¸ ì•Œ ìˆ˜ ìˆì—ˆë‹¤ . \\\\nì†Œë…€ëŠ” ê°œìš¸ì—ë‹¤ ì†ì„ ì ê·¸ê³  ë¬¼ì¥ë‚œì„ í•˜ê³  ìˆëŠ” ê²ƒì´ë‹¤ . ì„œìš¸ì„œëŠ” ì´ëŸ° ê°œìš¸ë¬¼ì„ ë³´ì§€ \\\\nëª»í•˜ê¸°ë‚˜ í•œ ë“¯ì´.\\\\në²Œì¨ ë©°ì¹ ì§¸ ì†Œë…€ëŠ” , í•™êµì—ì„œ ëŒì•„ì˜¤ëŠ” ê¸¸ì— ë¬¼ì¥ë‚œì´ì—ˆë‹¤ . ê·¸ëŸ°ë° , ì–´ì œê¹Œì§€ ê°œìš¸ ê¸°ìŠ­ì—\\\\nì„œ í•˜ë”ë‹ˆ , ì˜¤ëŠ˜ì€ ì§•ê²€ë‹¤ë¦¬ í•œê°€ìš´\\'\\nâ‘¡ ë°ì´í„° ë¶„í• \\nCharacterTextSplitter ë¡œ chunk_size ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œë¥¼ ìª¼ê°­ë‹ˆë‹¤. chunk_overlap ì— 50ê°œì˜ í† í°ì„ ì§€ì •í•˜ì—¬ ë¬¸ì„œ-ë¬¸ì„œ ê°„ ê²¹ì³ì§€ëŠ” ë¶€ë¶„(overlap) ì´ ìˆë„ë¡ í•˜ì—¬ ë¹„êµì  ìœ ì—°í•œ ìš”ì•½ ê²°ê³¼ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\\n```\\nfrom langchain.text_splitter import CharacterTextSplitter\\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\\ntexts = text_splitter.split_documents(document)\\n```\\nâ‘¢ ì €ì¥ ë° ê²€ìƒ‰\\nOpenAIEmbeddings ë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì„ë² ë”©í•œ ë’¤, Chroma ë²¡í„°ìŠ¤í† ì–´(vectorstore) ì— ì €ì¥í•©ë‹ˆë‹¤.\\në§ˆì§€ë§‰ ì¤„ì—ëŠ” as_retriever() ë¡œ retriever í˜•íƒœë¡œ ê°€ì ¸ì˜¤ëŠ”ë°, ì´ëŠ” ì¶”í›„ ì‚¬ìš©ìì˜ query ì…ë ¥ì‹œ, ì…ë ¥ëœ queryë¡œ vectorestoreì—ì„œ ìœ ì‚¬ì„±ì´ ë†’ì€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ ë‚¼ ë•Œ ì“°ì…ë‹ˆë‹¤.\\n```\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom langchain.vectorstores import Chroma\\nì„ë² ë”©\\nembeddings = OpenAIEmbeddings()\\nChroma DB ì— ì €ì¥\\ndocsearch = Chroma.from_documents(texts, embeddings)\\nretriever ê°€ì ¸ì˜´\\nretriever = docsearch.as_retriever()\\n```\\nâ‘£ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\\nì•„ë˜ì˜ ì˜ˆì œëŠ” langchain hub ì—ì„œ RAG Prompt ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.\\nì´ì²˜ëŸ¼ langchain hub ì—ì„œ ê³µê°œëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ê±°ë‚˜, ChatPromptTemplate ë¥¼ ì§ì ‘ ìƒì„±í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. ìì„¸í•œ ì‚¬í•­ì€ ConversationChain, í…œí”Œë¦¿ ì‚¬ìš©ë²• ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n```\\nlangchain hub ì—ì„œ Prompt ë‹¤ìš´ë¡œë“œ ì˜ˆì‹œ\\nhttps://smith.langchain.com/hub/rlm/rag-prompt\\nfrom langchain import hub\\nrag_prompt = hub.pull(\"rlm/rag-prompt\")\\nrag_prompt\\n```\\nChatPromptTemplate(input_variables=[\\'question\\', \\'context\\'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\\'question\\', \\'context\\'], output_parser=None, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\\\nQuestion: {question} \\\\nContext: {context} \\\\nAnswer:\", template_format=\\'f-string\\', validate_template=True), additional_kwargs={})])\\nâ‘¤ ìƒì„±\\në§ˆì§€ë§‰ ë‹¨ê³„ëŠ” LLM ëª¨ë¸ì„ ì •ì˜í•˜ê³  Chain ì„ ìƒì„±í•˜ëŠ” ë‹¨ê³„ ì…ë‹ˆë‹¤.\\n```\\nLLM\\nfrom langchain.chat_models import ChatOpenAI\\nChatGPT ëª¨ë¸ ì§€ì •\\nllm = ChatOpenAI(model_name=\"gpt-4-0613\", temperature=0)\\n```\\n```\\nRAG chain ìƒì„±\\nfrom langchain.schema.runnable import RunnablePassthrough\\npipe operatorë¥¼ í™œìš©í•œ ì²´ì¸ ìƒì„±\\nrag_chain = (\\n    {\"context\": retriever, \"question\": RunnablePassthrough()} \\n    | rag_prompt \\n    | llm \\n)\\n```\\nâ‘¥ í…ŒìŠ¤íŠ¸\\nrag_chain.invoke(\"ì´ ì†Œì„¤ì˜ ì œëª©ì€ ë­ì•¼?\")\\nAIMessage(content=\\'ì´ ì†Œì„¤ì˜ ì œëª©ì€ \"ì†Œë‚˜ê¸°\"ì…ë‹ˆë‹¤.\\', additional_kwargs={}, example=False)\\nrag_chain.invoke(\"ì´ ì†Œì„¤ì˜ ì €ìëŠ” ëˆ„êµ¬ì•¼?\")\\nAIMessage(content=\\'ì´ ì†Œì„¤ì˜ ì €ìëŠ” í™©ìˆœì›ì…ë‹ˆë‹¤.\\', additional_kwargs={}, example=False)\\níƒœê·¸: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, PDF, ë­ì²´ì¸, ë­ì²´ì¸ íŠœí† ë¦¬ì–¼, ë¬¸ì„œìš”ì•½, ì§ˆì˜ì‘ë‹µ, í¬ë¡¤ë§\\nì¹´í…Œê³ ë¦¬: langchain\\nì—…ë°ì´íŠ¸: 2023ë…„ 10ì›” 13ì¼\\nê³µìœ í•˜ê¸°\\nTwitter Facebook LinkedIn\\nì´ì „ ë‹¤ìŒ\\nëŒ“ê¸€ë‚¨ê¸°ê¸°\\nì°¸ê³ \\npoetry ì˜ ê±°ì˜ ëª¨ë“ ê²ƒ (íŠœí† ë¦¬ì–¼)\\n2024ë…„ 03ì›” 30ì¼ 5 ë¶„ ì†Œìš”\\nPython ê°œë°œì— ìˆì–´ì„œ poetryëŠ” ë§¤ìš° ê°•ë ¥í•œ ë„êµ¬ë¡œ, í”„ë¡œì íŠ¸ì˜ ì˜ì¡´ì„± ê´€ë¦¬ì™€ íŒ¨í‚¤ì§€ ë°°í¬ë¥¼ ê°„ì†Œí™”í•˜ëŠ” ë° í° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° poetry í™œìš© íŠœí† ë¦¬ì–¼ì„ ì‚´í´ ë³´ê² ìŠµë‹ˆë‹¤.\\nLangGraph Retrieval Agentë¥¼ í™œìš©í•œ ë™ì  ë¬¸ì„œ ê²€ìƒ‰ ë° ì²˜ë¦¬\\n2024ë…„ 03ì›” 06ì¼ 10 ë¶„ ì†Œìš”\\nLangGraph Retrieval AgentëŠ” ì–¸ì–´ ì²˜ë¦¬, AI ëª¨ë¸ í†µí•©, ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬, ê·¸ë˜í”„ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì–¸ì–´ ê¸°ë°˜ AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— í•„ìˆ˜ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤.\\n[Assistants API] Code Interpreter, Retrieval, Functions í™œìš©ë²•\\n2024ë…„ 02ì›” 13ì¼ 35 ë¶„ ì†Œìš”\\nOpenAIì˜ ìƒˆë¡œìš´ Assistants APIëŠ” ëŒ€í™”ì™€ ë”ë¶ˆì–´ ê°•ë ¥í•œ ë„êµ¬ ì ‘ê·¼ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì€ OpenAI Assistants APIë¥¼ í™œìš©í•˜ëŠ” ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤. íŠ¹íˆ, Assistant API ê°€ ì œê³µí•˜ëŠ” ë„êµ¬ì¸ Code Interpreter, Retrieval...\\n[LangChain] ì—ì´ì „íŠ¸(Agent)ì™€ ë„êµ¬(tools)ë¥¼ í™œìš©í•œ ì§€ëŠ¥í˜• ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ\\n2024ë…„ 02ì›” 09ì¼ 41 ë¶„ ì†Œìš”\\nì´ ê¸€ì—ì„œëŠ” LangChain ì˜ Agent í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ê²€ìƒ‰ê³¼ ë°ì´í„° ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. LangSmith ë¥¼ ì‚¬ìš©í•˜ì—¬ Agentì˜ ì¶”ë¡  ë‹¨ê³„ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. Agentê°€ í™œìš©í•  ê²€ìƒ‰ ë„êµ¬(Tavily Search), PDF ê¸°ë°˜ ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„...\\n\\níŒ”ë¡œìš°:\\nYouTube\\nGitHub\\nInstagram\\ní”¼ë“œ\\n\\nÂ© 2024 í…Œë””ë…¸íŠ¸. Powered by Jekyll & Minimal Mistakes.'}]\n"
     ]
    }
   ],
   "source": [
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬ í˜¸ì¶œ\n",
    "result = web_search_tool.search(\"í…Œë””ë…¸íŠ¸ ìœ„í‚¤ë…ìŠ¤ ë­ì²´ì¸ íŠœí† ë¦¬ì–¼ URL ì„ ì•Œë ¤ì£¼ì„¸ìš”\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1904c95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1) - í…Œë””ë…¸íŠ¸',\n",
       " 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-01/',\n",
       " 'content': 'â‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€ â‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ â‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ â‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1) 2023ë…„ 09ì›” 28ì¼ 5 ë¶„ ì†Œìš” ëª©ì°¨ ğŸŒ± ë­ì²´ì¸ì˜ ì£¼ìš” ê¸°ëŠ¥ ğŸŒ± í™˜ê²½ì„¤ì • API KEY ë°œê¸‰ ëª¨ë“ˆ ì„¤ì¹˜(openai, langchain) ğŸ”¥ ChatOpenAI ğŸ”¥ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ í™œìš© LLMChain ê°ì²´ â‘  run() â‘¡ apply() â‘¢ generate() â‘£ 2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ ì•ˆì— ì •ì˜ â‘¤ ìŠ¤íŠ¸ë¦¬ë°(streaming) ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì¸ ë­ì²´ì¸(LangChain) ì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ ë‹¤ë¤„ë³´ê³ ì í•©ë‹ˆë‹¤. íŠœí† ë¦¬ì–¼ì€ ì‹œë¦¬ì¦ˆ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´, ì‹œë¦¬ì¦ˆë¥¼ ê±°ë“­í•˜ë©´ì„œ ë­ì²´ì¸(LangChain) ì„ í†µí•´ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì€ ë”ìš± ê°„ê²°í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ë¡  ëŠ¥ë ¥: ì œê³µëœ ë¬¸ë§¥ì— ê¸°ë°˜í•˜ì—¬ ì–´ë–¤ ëŒ€ë‹µì„ í• ì§€, ë˜ëŠ” ì–´ë– í•œ ì•¡ì…˜ì„ ì·¨í• ì§€ì— ëŒ€í•œ ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. íŠ¹íˆ, ì´ëŸ¬í•œ ì‚¬ìš© ì¤€ë¹„ëœ ì²´ì¸ì€ ì´ˆë³´ìë„ ë­ì²´ì¸ì„ ì‰½ê²Œ ì‹œì‘í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ë©°, ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê³„íší•˜ëŠ” ì „ë¬¸ê°€ë“¤ì€ ê¸°ì¡´ ì²´ì¸ì„ ì†ì‰½ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ê±°ë‚˜ ìƒˆë¡­ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.',\n",
       " 'score': 0.6506676,\n",
       " 'raw_content': \"ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1) - í…Œë””ë…¸íŠ¸\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\ní…Œë””ë…¸íŠ¸ ë°ì´í„°ì™€ ì¸ê³µì§€ëŠ¥ì„ ì¢‹ì•„í•˜ëŠ” ê°œë°œì ë…¸íŠ¸\\n\\nê²€ìƒ‰\\nì¹´í…Œê³ ë¦¬\\níƒœê·¸\\nì—°ë„\\nê°•ì˜\\nì–´ë°”ì›ƒë¯¸\\n\\ní† ê¸€ ë©”ë‰´\\n\\nHome \\n/3.  Langchain \\n/5.  ë­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1)\\n\\nğŸ”¥ì•Œë¦¼ğŸ”¥\\nâ‘  í…Œë””ë…¸íŠ¸ ìœ íŠœë¸Œ - êµ¬ê²½í•˜ëŸ¬ ê°€ê¸°!\\nâ‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€\\nâ‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ\\nâ‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ\\nâ‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ\\në­ì²´ì¸(langchain)ì˜ OpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²• (1)\\n2023ë…„ 09ì›” 28ì¼ 5 ë¶„ ì†Œìš”\\nëª©ì°¨\\n\\nğŸŒ± ë­ì²´ì¸ì˜ ì£¼ìš” ê¸°ëŠ¥\\nğŸŒ± í™˜ê²½ì„¤ì •\\nAPI KEY ë°œê¸‰\\nëª¨ë“ˆ ì„¤ì¹˜(openai, langchain)\\n\\n\\nğŸ”¥ ChatOpenAI\\nğŸ”¥ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ í™œìš©\\nLLMChain ê°ì²´\\nâ‘  run()\\nâ‘¡ apply()\\nâ‘¢ generate()\\nâ‘£ 2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ ì•ˆì— ì •ì˜\\nâ‘¤ ìŠ¤íŠ¸ë¦¬ë°(streaming)\\n\\n\\n\\nì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì¸ ë­ì²´ì¸(LangChain) ì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ ë‹¤ë¤„ë³´ê³ ì í•©ë‹ˆë‹¤.\\níŠœí† ë¦¬ì–¼ì€ ì‹œë¦¬ì¦ˆ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´, ì‹œë¦¬ì¦ˆë¥¼ ê±°ë“­í•˜ë©´ì„œ ë­ì²´ì¸(LangChain) ì„ í†µí•´ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì€ ë”ìš± ê°„ê²°í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nğŸŒ± ë­ì²´ì¸ì˜ ì£¼ìš” ê¸°ëŠ¥\\në­ì²´ì¸ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°–ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në¬¸ë§¥ ì¸ì‹: ì–¸ì–´ ëª¨ë¸ê³¼ ë‹¤ì–‘í•œ ë¬¸ë§¥ ì†ŒìŠ¤(í”„ë¡¬í”„íŠ¸ ì§€ì‹œ, ì˜ˆì œ, ì‘ë‹µì˜ ê·¼ê±° ë‚´ìš© ë“±)ë¥¼ ì—°ë™í•˜ë©°, ì‚¬ìš©ìì˜ ë¬¸ë§¥ì„ ì •í™•íˆ ì´í•´í•©ë‹ˆë‹¤.\\nì¶”ë¡  ëŠ¥ë ¥: ì œê³µëœ ë¬¸ë§¥ì— ê¸°ë°˜í•˜ì—¬ ì–´ë–¤ ëŒ€ë‹µì„ í• ì§€, ë˜ëŠ” ì–´ë– í•œ ì•¡ì…˜ì„ ì·¨í• ì§€ì— ëŒ€í•œ ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n\\në­ì²´ì¸ì˜ ê°€ì¹˜\\në­ì²´ì¸ì˜ í•µì‹¬ì ì¸ ê°€ì¹˜ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆì§€ë§Œ, ê·¸ ì¤‘ì—ì„œë„ ë‘ ê°€ì§€ ì£¼ìš”í•œ ì ì„ ê¼½ìë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\nêµ¬ì„± ìš”ì†Œ: ì‚¬ìš©ìëŠ” ì–¸ì–´ ëª¨ë¸ê³¼ì˜ ìƒí˜¸ì‘ìš©ì„ ìœ„í•´ ë‹¤ì–‘í•œ êµ¬ì„± ìš”ì†Œì™€ ì¶”ìƒí™”ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†ŒëŠ” ê°œë³„ì ìœ¼ë¡œ, ë˜ëŠ” ë­ì²´ì¸ í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ëª¨ë“ˆì‹ìœ¼ë¡œ ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì‚¬ìš© ì¤€ë¹„ëœ ì²´ì¸: íŠ¹ì • ê³ ìˆ˜ì¤€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë¯¸ë¦¬ ì¡°ë¦½ëœ êµ¬ì„± ìš”ì†Œì˜ íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤.\\n\\níŠ¹íˆ, ì´ëŸ¬í•œ ì‚¬ìš© ì¤€ë¹„ëœ ì²´ì¸ì€ ì´ˆë³´ìë„ ë­ì²´ì¸ì„ ì‰½ê²Œ ì‹œì‘í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ë©°, ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê³„íší•˜ëŠ” ì „ë¬¸ê°€ë“¤ì€ ê¸°ì¡´ ì²´ì¸ì„ ì†ì‰½ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ê±°ë‚˜ ìƒˆë¡­ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.\\nğŸŒ± í™˜ê²½ì„¤ì •\\nAPI KEY ë°œê¸‰\\në¨¼ì €, openai ì˜ API KEY ë¥¼ ë°œê¸‰ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤. ë°œê¸‰ì€ ë‹¤ìŒì˜ ì ˆì°¨ë¥¼ í†µí•´ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nhttps://platform.openai.com/account/api-keys ë¡œ ì ‘ì†í•©ë‹ˆë‹¤.\\n\\nLog in ë²„íŠ¼ì„ í´ë¦­ í›„ ê³„ì •ì— ë¡œê·¸ì¸ í•©ë‹ˆë‹¤. ê³„ì •ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì€ ê²½ìš°ì—ëŠ” Sign up ìœ¼ë¡œ íšŒì›ê°€ì… í›„ ë¡œê·¸ì¸ í•©ë‹ˆë‹¤.\\n\\n\\n\\nâ€œCreate new secret keyâ€ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒˆë¡œìš´ í‚¤ë¥¼ ë°œê¸‰í•©ë‹ˆë‹¤.\\n\\n\\n\\nName ì—ëŠ” ë°œê¸‰í•˜ëŠ” í‚¤ì— ëŒ€í•œ ë³„ì¹­ì„ ì…ë ¥í•©ë‹ˆë‹¤.\\n\\n\\n\\nìƒˆë¡­ê²Œ ë°œê¸‰í•œ í‚¤ë¥¼ ë³µì‚¬í•©ë‹ˆë‹¤. ìƒì–´ë²„ë¦¬ë©´ ë‹¤ì‹œ ë°œê¸‰í•˜ì—¬ì•¼ í•˜ë¯€ë¡œ, ì•ˆì „í•œ ê³³ì— ì €ì¥í•´ ë‘¡ë‹ˆë‹¤.\\n\\n\\nëª¨ë“ˆ ì„¤ì¹˜(openai, langchain)\\npip ëª…ë ¹ì–´ë¡œ ëª¨ë“ˆì„ ì„¤ì¹˜ í•©ë‹ˆë‹¤. ì•„ë‚˜ì½˜ë‹¤ ê°€ìƒí™˜ê²½ì—ì„œ ì„¤ì¹˜í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.\\n```\\nopenai íŒŒì´ì¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜\\npip install openai langchain\\n```\\në¨¼ì €, ì„¤ì¹˜í•œ openai ëª¨ë“ˆì„ import í•œ ë’¤, ë°œê¸‰ë°›ì€ API KEYë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•©ë‹ˆë‹¤.\\n```\\nimport os\\nos.environ['OPENAI_API_KEY'] = 'OPENAI API KEY ì…ë ¥'\\n```\\nì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\\n```\\nimport openai\\nmodel_list = sorted([m['id'] for m in openai.Model.list()['data']])\\nfor m in model_list:\\n    print(m)\\n```\\nada\\nada-code-search-code\\nada-code-search-text\\nada-search-document\\nada-search-query\\nada-similarity\\nbabbage\\nbabbage-002\\nbabbage-code-search-code\\nbabbage-code-search-text\\nbabbage-search-document\\nbabbage-search-query\\nbabbage-similarity\\ncode-davinci-edit-001\\ncode-search-ada-code-001\\ncode-search-ada-text-001\\ncode-search-babbage-code-001\\ncode-search-babbage-text-001\\ncurie\\ncurie-instruct-beta\\ncurie-search-document\\ncurie-search-query\\ncurie-similarity\\ndavinci\\ndavinci-002\\ndavinci-instruct-beta\\ndavinci-search-document\\ndavinci-search-query\\ndavinci-similarity\\ngpt-3.5-turbo\\ngpt-3.5-turbo-0301\\ngpt-3.5-turbo-0613\\ngpt-3.5-turbo-16k\\ngpt-3.5-turbo-16k-0613\\ngpt-3.5-turbo-instruct\\ngpt-3.5-turbo-instruct-0914\\ngpt-4\\ngpt-4-0314\\ngpt-4-0613\\ntext-ada-001\\ntext-babbage-001\\ntext-curie-001\\ntext-davinci-001\\ntext-davinci-002\\ntext-davinci-003\\ntext-davinci-edit-001\\ntext-embedding-ada-002\\ntext-search-ada-doc-001\\ntext-search-ada-query-001\\ntext-search-babbage-doc-001\\ntext-search-babbage-query-001\\ntext-search-curie-doc-001\\ntext-search-curie-query-001\\ntext-search-davinci-doc-001\\ntext-search-davinci-query-001\\ntext-similarity-ada-001\\ntext-similarity-babbage-001\\ntext-similarity-curie-001\\ntext-similarity-davinci-001\\nwhisper-1\\nğŸ”¥ ChatOpenAI\\nOpenAI ì‚¬ì˜ ì±„íŒ… ì „ìš© Large Language Model(llm) ì…ë‹ˆë‹¤.\\nê°ì²´ë¥¼ ìƒì„±í•  ë•Œ ë‹¤ìŒì„ ì˜µì…˜ ê°’ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜µì…˜ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\ntemperature\\n\\nì‚¬ìš©í•  ìƒ˜í”Œë§ ì˜¨ë„ëŠ” 0ê³¼ 2 ì‚¬ì´ì—ì„œ ì„ íƒí•©ë‹ˆë‹¤. 0.8ê³¼ ê°™ì€ ë†’ì€ ê°’ì€ ì¶œë ¥ì„ ë” ë¬´ì‘ìœ„í•˜ê²Œ ë§Œë“¤ê³ , 0.2ì™€ ê°™ì€ ë‚®ì€ ê°’ì€ ì¶œë ¥ì„ ë” ì§‘ì¤‘ë˜ê³  ê²°ì •ë¡ ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.\\n\\nmax_tokens\\n\\nì±„íŒ… ì™„ì„±ì—ì„œ ìƒì„±í•  í† í°ì˜ ìµœëŒ€ ê°œìˆ˜ì…ë‹ˆë‹¤.\\n\\nmodel_name: ì ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸\\n\\n\\ngpt-3.5-turbo\\n\\n\\ngpt-3.5-turbo-0301\\n\\n\\ngpt-3.5-turbo-0613\\n\\n\\ngpt-3.5-turbo-16k\\n\\n\\ngpt-3.5-turbo-16k-0613\\n\\n\\ngpt-3.5-turbo-instruct\\n\\n\\ngpt-3.5-turbo-instruct-0914\\n\\n\\ngpt-4\\n\\n\\ngpt-4-0314\\n\\n\\ngpt-4-0613\\n\\n\\n```\\nfrom langchain.chat_models import ChatOpenAI\\nê°ì²´ ìƒì„±\\nllm = ChatOpenAI(temperature=0,               # ì°½ì˜ì„± (0.0 ~ 2.0) \\n                 max_tokens=2048,             # ìµœëŒ€ í† í°ìˆ˜\\n                 model_name='gpt-3.5-turbo',  # ëª¨ë¸ëª…\\n                )\\nì§ˆì˜ë‚´ìš©\\nquestion = 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ë­ì•¼?'\\nì§ˆì˜\\nprint(f'[ë‹µë³€]: {llm.predict(question)}')\\n```\\n[ë‹µë³€]: ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\\nğŸ”¥ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ í™œìš©\\nPromptTemplate\\n\\n\\nì‚¬ìš©ìì˜ ì…ë ¥ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ ë§Œë“œëŠ” ë° ì‚¬ìš©ë˜ëŠ” í…œí”Œë¦¿ì…ë‹ˆë‹¤\\n\\n\\nì‚¬ìš©ë²•\\n\\n\\ntemplate: í…œí”Œë¦¿ ë¬¸ìì—´ì…ë‹ˆë‹¤. ì´ ë¬¸ìì—´ ë‚´ì—ì„œ ì¤‘ê´„í˜¸ {}ëŠ” ë³€ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n\\n\\ninput_variables: ì¤‘ê´„í˜¸ ì•ˆì— ë“¤ì–´ê°ˆ ë³€ìˆ˜ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜í•©ë‹ˆë‹¤.\\n\\n\\n\\n\\ninput_variables\\n\\n\\ninput_variablesëŠ” PromptTemplateì—ì„œ ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ì˜ ì´ë¦„ì„ ì •ì˜í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\\n\\n\\nì‚¬ìš©ë²•: ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€ìˆ˜ ì´ë¦„ì„ ì •ì˜í•©ë‹ˆë‹¤.\\n\\n\\n```\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.chains import LLMChain\\nì§ˆë¬¸ í…œí”Œë¦¿ í˜•ì‹ ì •ì˜\\ntemplate = '{country}ì˜ ìˆ˜ë„ëŠ” ë­ì•¼?'\\ní…œí”Œë¦¿ ì™„ì„±\\nprompt = PromptTemplate(template=template, input_variables=['country'])\\n```\\nLLMChain ê°ì²´\\nLLMChain\\n\\n\\nLLMChainì€ íŠ¹ì • PromptTemplateì™€ ì—°ê²°ëœ ì²´ì¸ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\\n\\n\\nì‚¬ìš©ë²•\\n\\n\\nprompt: ì•ì„œ ì •ì˜í•œ PromptTemplate ê°ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\\n\\n\\nllm: ì–¸ì–´ ëª¨ë¸ì„ ë‚˜íƒ€ë‚´ë©°, ì´ ì˜ˆì‹œì—ì„œëŠ” ì´ë¯¸ ì–´ë”˜ê°€ì—ì„œ ì •ì˜ëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\\n\\n\\n\\n\\n```\\nì—°ê²°ëœ ì²´ì¸(Chain)ê°ì²´ ìƒì„±\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\nâ‘  run()\\nrun() í•¨ìˆ˜ë¡œ í…œí”Œë¦¿ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰\\n```\\nì²´ì¸ ì‹¤í–‰: run()\\nprint(llm_chain.run(country='ì¼ë³¸'))\\n```\\nì¼ë³¸ì˜ ìˆ˜ë„ëŠ” ë„ì¿„ì…ë‹ˆë‹¤.\\n```\\nì²´ì¸ ì‹¤í–‰: run()\\nprint(llm_chain.run(country='ìºë‚˜ë‹¤'))\\n```\\nìºë‚˜ë‹¤ì˜ ìˆ˜ë„ëŠ” ì˜¤íƒ€ì™€(Ottawa)ì…ë‹ˆë‹¤.\\nâ‘¡ apply()\\napply() í•¨ìˆ˜ë¡œ ì—¬ëŸ¬ê°œì˜ ì…ë ¥ì„ í•œ ë²ˆì— ì‹¤í–‰\\n```\\ninput_list = [\\n    {'country': 'í˜¸ì£¼'},\\n    {'country': 'ì¤‘êµ­'},\\n    {'country': 'ë„¤ëœë€ë“œ'}\\n]\\nllm_chain.apply(input_list)\\n```\\n[{'text': 'í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.'},\\n {'text': 'ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.'},\\n {'text': 'ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.'}]\\ntext í‚¤ ê°’ìœ¼ë¡œ ê²°ê³¼ ë­‰ì¹˜ê°€ ë°˜í™˜ë˜ì—ˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì´ë¥¼ ë°˜ë³µë¬¸ìœ¼ë¡œ ì¶œë ¥í•œë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n```\\ninput_list ì— ëŒ€í•œ ê²°ê³¼ ë°˜í™˜\\nresult = llm_chain.apply(input_list)\\në°˜ë³µë¬¸ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥\\nfor res in result:\\n    print(res['text'].strip())\\n```\\ní˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.\\nì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.\\në„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.\\nâ‘¢ generate()\\ngenerate() ëŠ” ë¬¸ìì—´ ëŒ€ì‹ ì— LLMResultë¥¼ ë°˜í™˜í•˜ëŠ” ì ì„ ì œì™¸í•˜ê³ ëŠ” applyì™€ ìœ ì‚¬í•©ë‹ˆë‹¤.\\nLLMResultëŠ” í† í° ì‚¬ìš©ëŸ‰ê³¼ ì¢…ë£Œ ì´ìœ ì™€ ê°™ì€ ìœ ìš©í•œ ìƒì„± ì •ë³´ë¥¼ ìì£¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\\n```\\ninput_list ì— ëŒ€í•œ ê²°ê³¼ ë°˜í™˜\\ngenerated_result = llm_chain.generate(input_list)\\nprint(generated_result)\\n```\\ngenerations=[[ChatGeneration(text='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))], [ChatGeneration(text='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))], [ChatGeneration(text='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\në‹µë³€ ì¶œë ¥\\ngenerated_result.generations\\n```\\n[[ChatGeneration(text='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='í˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='ë„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.', additional_kwargs={}, example=False))]]\\n```\\ní† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥\\ngenerated_result.llm_output\\n```\\n{'token_usage': {'prompt_tokens': 58,\\n  'completion_tokens': 57,\\n  'total_tokens': 115},\\n 'model_name': 'gpt-3.5-turbo'}\\n```\\nrun ID ì¶œë ¥\\ngenerated_result.run\\n```\\n[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')),\\n RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')),\\n RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\në‹µë³€ ì¶œë ¥\\nfor gen in generated_result.generations:\\n    print(gen[0].text.strip())\\n```\\ní˜¸ì£¼ì˜ ìˆ˜ë„ëŠ” ìº”ë²„ë¼ì…ë‹ˆë‹¤.\\nì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•(åŒ—äº¬)ì…ë‹ˆë‹¤.\\në„¤ëœë€ë“œì˜ ìˆ˜ë„ëŠ” ì•”ìŠ¤í…Œë¥´ë‹´(Amsterdam)ì…ë‹ˆë‹¤.\\nâ‘£ 2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ ì•ˆì— ì •ì˜\\n2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ í…œí”Œë¦¿ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì´ë²ˆì—ëŠ” 2ê°œ ì´ìƒì˜ ë³€ìˆ˜(input_variables) ë¥¼ í™œìš©í•˜ì—¬ í…œí”Œë¦¿ êµ¬ì„±ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤.\\n```\\nì§ˆë¬¸ í…œí”Œë¦¿ í˜•ì‹ ì •ì˜\\ntemplate = '{area1} ì™€ {area2} ì˜ ì‹œì°¨ëŠ” ëª‡ì‹œê°„ì´ì•¼?'\\ní…œí”Œë¦¿ ì™„ì„±\\nprompt = PromptTemplate(template=template, input_variables=['area1', 'area2'])\\nì—°ê²°ëœ ì²´ì¸(Chain)ê°ì²´ ìƒì„±\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n```\\nì²´ì¸ ì‹¤í–‰: run()\\nprint(llm_chain.run(area1='ì„œìš¸', area2='íŒŒë¦¬'))\\n```\\nì„œìš¸ê³¼ íŒŒë¦¬ì˜ ì‹œì°¨ëŠ” 8ì‹œê°„ì…ë‹ˆë‹¤. ì„œìš¸ì´ íŒŒë¦¬ë³´ë‹¤ 8ì‹œê°„ ì•ì„œ ìˆìŠµë‹ˆë‹¤.\\n```\\ninput_list = [\\n    {'area1': 'íŒŒë¦¬', 'area2': 'ë‰´ìš•'},\\n    {'area1': 'ì„œìš¸', 'area2': 'í•˜ì™€ì´'},\\n    {'area1': 'ì¼„ë²„ë¼', 'area2': 'ë² ì´ì§•'}\\n]\\në°˜ë³µë¬¸ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥\\nresult = llm_chain.apply(input_list)\\nfor res in result:\\n    print(res['text'].strip())\\n```\\níŒŒë¦¬ì™€ ë‰´ìš•ì˜ ì‹œì°¨ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 6ì‹œê°„ì…ë‹ˆë‹¤. íŒŒë¦¬ê°€ ë‰´ìš•ë³´ë‹¤ 6ì‹œê°„ ì•ì„œ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŒŒë¦¬ê°€ ì˜¤ì „ 9ì‹œë¼ë©´ ë‰´ìš•ì€ ì˜¤ì „ 3ì‹œì…ë‹ˆë‹¤.\\nì„œìš¸ê³¼ í•˜ì™€ì´ì˜ ì‹œì°¨ëŠ” ì„œìš¸ì´ í•˜ì™€ì´ë³´ë‹¤ 19ì‹œê°„ ë¹ ë¦…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì„œìš¸ì´ ì˜¤ì „ 9ì‹œë¼ë©´ í•˜ì™€ì´ëŠ” ì „ë‚  ì˜¤í›„ 2ì‹œì…ë‹ˆë‹¤.\\nì¼„ë²„ë¼ì™€ ë² ì´ì§•ì˜ ì‹œì°¨ëŠ” 2ì‹œê°„ì…ë‹ˆë‹¤. ì¼„ë²„ë¼ëŠ” ì˜¤ìŠ¤íŠ¸ë ˆì¼ë¦¬ì•„ì˜ ìˆ˜ë„ë¡œ UTC+10 ì‹œê°„ëŒ€ì— ìœ„ì¹˜í•˜ê³ , ë² ì´ì§•ì€ ì¤‘êµ­ì˜ ìˆ˜ë„ë¡œ UTC+8 ì‹œê°„ëŒ€ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.\\nâ‘¤ ìŠ¤íŠ¸ë¦¬ë°(streaming)\\nìŠ¤íŠ¸ë¦¬ë° ì˜µì…˜ì€ ì§ˆì˜ì— ëŒ€í•œ ë‹µë³€ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\\në‹¤ìŒê³¼ ê°™ì´ streaming=True ë¡œ ì„¤ì •í•˜ê³  ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹µë³€ì„ ë°›ê¸° ìœ„í•œ StreamingStdOutCallbackHandler() ì„ ì½œë°±ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.\\n```\\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\\nê°ì²´ ìƒì„±\\nllm = ChatOpenAI(temperature=0,               # ì°½ì˜ì„± (0.0 ~ 2.0) \\n                 max_tokens=2048,             # ìµœëŒ€ í† í°ìˆ˜\\n                 model_name='gpt-3.5-turbo',  # ëª¨ë¸ëª…\\n                 streaming=True,            \\n                 callbacks=[StreamingStdOutCallbackHandler()]\\n                )\\n```\\n```\\nì§ˆì˜ë‚´ìš©\\nquestion = 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ë­ì•¼?'\\nìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹µë³€ ì¶œë ¥\\nresponse = llm.predict(question)\\n```\\nëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\\níƒœê·¸: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, ë­ì²´ì¸, ë­ì²´ì¸ íŠœí† ë¦¬ì–¼\\nì¹´í…Œê³ ë¦¬: langchain\\nì—…ë°ì´íŠ¸: 2023ë…„ 09ì›” 28ì¼\\nê³µìœ í•˜ê¸°\\nTwitter Facebook LinkedIn\\nì´ì „ ë‹¤ìŒ\\nëŒ“ê¸€ë‚¨ê¸°ê¸°\\nì°¸ê³ \\npoetry ì˜ ê±°ì˜ ëª¨ë“ ê²ƒ (íŠœí† ë¦¬ì–¼)\\n2024ë…„ 03ì›” 30ì¼ 5 ë¶„ ì†Œìš”\\nPython ê°œë°œì— ìˆì–´ì„œ poetryëŠ” ë§¤ìš° ê°•ë ¥í•œ ë„êµ¬ë¡œ, í”„ë¡œì íŠ¸ì˜ ì˜ì¡´ì„± ê´€ë¦¬ì™€ íŒ¨í‚¤ì§€ ë°°í¬ë¥¼ ê°„ì†Œí™”í•˜ëŠ” ë° í° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° poetry í™œìš© íŠœí† ë¦¬ì–¼ì„ ì‚´í´ ë³´ê² ìŠµë‹ˆë‹¤.\\nLangGraph Retrieval Agentë¥¼ í™œìš©í•œ ë™ì  ë¬¸ì„œ ê²€ìƒ‰ ë° ì²˜ë¦¬\\n2024ë…„ 03ì›” 06ì¼ 10 ë¶„ ì†Œìš”\\nLangGraph Retrieval AgentëŠ” ì–¸ì–´ ì²˜ë¦¬, AI ëª¨ë¸ í†µí•©, ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬, ê·¸ë˜í”„ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì–¸ì–´ ê¸°ë°˜ AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— í•„ìˆ˜ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤.\\n[Assistants API] Code Interpreter, Retrieval, Functions í™œìš©ë²•\\n2024ë…„ 02ì›” 13ì¼ 35 ë¶„ ì†Œìš”\\nOpenAIì˜ ìƒˆë¡œìš´ Assistants APIëŠ” ëŒ€í™”ì™€ ë”ë¶ˆì–´ ê°•ë ¥í•œ ë„êµ¬ ì ‘ê·¼ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì€ OpenAI Assistants APIë¥¼ í™œìš©í•˜ëŠ” ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤. íŠ¹íˆ, Assistant API ê°€ ì œê³µí•˜ëŠ” ë„êµ¬ì¸ Code Interpreter, Retrieval...\\n[LangChain] ì—ì´ì „íŠ¸(Agent)ì™€ ë„êµ¬(tools)ë¥¼ í™œìš©í•œ ì§€ëŠ¥í˜• ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ\\n2024ë…„ 02ì›” 09ì¼ 41 ë¶„ ì†Œìš”\\nì´ ê¸€ì—ì„œëŠ” LangChain ì˜ Agent í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ê²€ìƒ‰ê³¼ ë°ì´í„° ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. LangSmith ë¥¼ ì‚¬ìš©í•˜ì—¬ Agentì˜ ì¶”ë¡  ë‹¨ê³„ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. Agentê°€ í™œìš©í•  ê²€ìƒ‰ ë„êµ¬(Tavily Search), PDF ê¸°ë°˜ ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„...\\n\\níŒ”ë¡œìš°:\\nYouTube\\nGitHub\\nInstagram\\ní”¼ë“œ\\n\\nÂ© 2024 í…Œë””ë…¸íŠ¸. Powered by Jekyll & Minimal Mistakes.\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì›¹ ê²€ìƒ‰ ê²°ê³¼ì˜ ì²« ë²ˆì§¸ ê²°ê³¼ í™•ì¸\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac37855",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab91c2",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ ìƒíƒœ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d23ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "\n",
    "# ê·¸ë˜í”„ì˜ ìƒíƒœ ì •ì˜\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° ëª¨ë¸\n",
    "\n",
    "    Attributes:\n",
    "        question: ì§ˆë¬¸\n",
    "        generation: LLM ìƒì„±ëœ ë‹µë³€\n",
    "        documents: ë„íë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "\n",
    "    question: Annotated[str, \"User question\"]\n",
    "    generation: Annotated[str, \"LLM generated answer\"]\n",
    "    documents: Annotated[List[str], \"List of documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266cc42",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ íë¦„ ì •ì˜\n",
    "\n",
    "**ê·¸ë˜í”„ íë¦„**ì„ ì •ì˜í•˜ì—¬ **Adaptive RAG**ì˜ ì‘ë™ ë°©ì‹ì„ ëª…í™•íˆ í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œëŠ” ê·¸ë˜í”„ì˜ ìƒíƒœì™€ ì „í™˜ì„ ì„¤ì •í•˜ì—¬ ì¿¼ë¦¬ ì²˜ë¦¬ì˜ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
    "\n",
    "- **ìƒíƒœ ì •ì˜**: ê·¸ë˜í”„ì˜ ê° ìƒíƒœë¥¼ ëª…í™•íˆ ì •ì˜í•˜ì—¬ ì¿¼ë¦¬ì˜ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•©ë‹ˆë‹¤.\n",
    "- **ì „í™˜ ì„¤ì •**: ìƒíƒœ ê°„ì˜ ì „í™˜ì„ ì„¤ì •í•˜ì—¬ ì¿¼ë¦¬ê°€ ì ì ˆí•œ ê²½ë¡œë¥¼ ë”°ë¼ ì§„í–‰ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "- **íë¦„ ìµœì í™”**: ê·¸ë˜í”„ì˜ íë¦„ì„ ìµœì í™”í•˜ì—¬ ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì˜ ì •í™•ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bf00c",
   "metadata": {},
   "source": [
    "### ë…¸ë“œ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee6f34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ\n",
    "def retrieve(state):\n",
    "    print(\"==== [RETRIEVE] ====\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    documents = pdf_retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "# ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "def generate(state):\n",
    "    print(\"==== [GENERATE] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG ë‹µë³€ ìƒì„±\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ\n",
    "def grade_documents(state):\n",
    "    print(\"==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # ê° ë¬¸ì„œì— ëŒ€í•œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            # ê´€ë ¨ì„±ì´ ìˆëŠ” ë¬¸ì„œ ì¶”ê°€\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            # ê´€ë ¨ì„±ì´ ì—†ëŠ” ë¬¸ì„œëŠ” ê±´ë„ˆë›°ê¸°\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs}\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ ì¬ì‘ì„± ë…¸ë“œ\n",
    "def transform_query(state):\n",
    "    print(\"==== [TRANSFORM QUERY] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # ì§ˆë¬¸ ì¬ì‘ì„±\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"question\": better_question}\n",
    "\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ ë…¸ë“œ\n",
    "def web_search(state):\n",
    "    print(\"==== [WEB SEARCH] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    web_results_docs = [\n",
    "        Document(\n",
    "            page_content=web_result[\"content\"],\n",
    "            metadata={\"source\": web_result[\"url\"]},\n",
    "        )\n",
    "        for web_result in web_results\n",
    "    ]\n",
    "\n",
    "    return {\"documents\": web_results_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec62cc",
   "metadata": {},
   "source": [
    "## ì¶”ê°€ ë…¸ë“œ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d33976b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ ë¼ìš°íŒ… ë…¸ë“œ\n",
    "def route_question(state):\n",
    "    print(\"==== [ROUTE QUESTION] ====\")\n",
    "    # ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    # ì§ˆë¬¸ ë¼ìš°íŒ…\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    # ì§ˆë¬¸ ë¼ìš°íŒ… ê²°ê³¼ì— ë”°ë¥¸ ë…¸ë“œ ë¼ìš°íŒ…\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"==== [ROUTE QUESTION TO WEB SEARCH] ====\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"==== [ROUTE QUESTION TO VECTORSTORE] ====\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ\n",
    "def decide_to_generate(state):\n",
    "    print(\"==== [DECISION TO GENERATE] ====\")\n",
    "    # ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # ëª¨ë“  ë¬¸ì„œê°€ ê´€ë ¨ì„± ì—†ëŠ” ê²½ìš° ì§ˆë¬¸ ì¬ì‘ì„±\n",
    "        print(\n",
    "            \"==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš° ë‹µë³€ ìƒì„±\n",
    "        print(\"==== [DECISION: GENERATE] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def hallucination_check(state):\n",
    "    print(\"==== [CHECK HALLUCINATIONS] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # í™˜ê° í‰ê°€\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Hallucination ì—¬ë¶€ í™•ì¸\n",
    "    if grade == \"yes\":\n",
    "        print(\"==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\")\n",
    "\n",
    "        # ë‹µë³€ì˜ ê´€ë ¨ì„±(Relevance) í‰ê°€\n",
    "        print(\"==== [GRADE GENERATED ANSWER vs QUESTION] ====\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "\n",
    "        # ê´€ë ¨ì„± í‰ê°€ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬\n",
    "        if grade == \"yes\":\n",
    "            print(\"==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\")\n",
    "            return \"relevant\"\n",
    "        else:\n",
    "            print(\"==== [DECISION: GENERATED ANSWER DOES NOT ADDRESS QUESTION] ====\")\n",
    "            return \"not relevant\"\n",
    "    else:\n",
    "        print(\"==== [DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY] ====\")\n",
    "        return \"hallucination\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412119d",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "\n",
    "**ê·¸ë˜í”„ ì»´íŒŒì¼** ë‹¨ê³„ì—ì„œëŠ” **Adaptive RAG**ì˜ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ìƒíƒœë¡œ ë§Œë“­ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ê·¸ë˜í”„ì˜ ê° ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì—°ê²°í•˜ì—¬ ì¿¼ë¦¬ ì²˜ë¦¬ì˜ ì „ì²´ íë¦„ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ë…¸ë“œ ì •ì˜**: ê° ë…¸ë“œë¥¼ ì •ì˜í•˜ì—¬ ê·¸ë˜í”„ì˜ ìƒíƒœì™€ ì „í™˜ì„ ëª…í™•íˆ í•©ë‹ˆë‹¤.\n",
    "- **ì—£ì§€ ì„¤ì •**: ë…¸ë“œ ê°„ì˜ ì—£ì§€ë¥¼ ì„¤ì •í•˜ì—¬ ì¿¼ë¦¬ê°€ ì ì ˆí•œ ê²½ë¡œë¥¼ ë”°ë¼ ì§„í–‰ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "- **ì›Œí¬í”Œë¡œìš° êµ¬ì¶•**: ê·¸ë˜í”„ì˜ ì „ì²´ íë¦„ì„ êµ¬ì¶•í•˜ì—¬ ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì˜ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c106a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒíƒœ ì´ˆê¸°í™”\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ë…¸ë“œ ì •ì˜\n",
    "workflow.add_node(\"web_search\", web_search)  # ì›¹ ê²€ìƒ‰\n",
    "workflow.add_node(\"retrieve\", retrieve)  # ë¬¸ì„œ ê²€ìƒ‰\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # ë¬¸ì„œ í‰ê°€\n",
    "workflow.add_node(\"generate\", generate)  # ë‹µë³€ ìƒì„±\n",
    "workflow.add_node(\"transform_query\", transform_query)  # ì¿¼ë¦¬ ë³€í™˜\n",
    "\n",
    "# ê·¸ë˜í”„ ë¹Œë“œ\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_question,\n",
    "    {\n",
    "        \"web_search\": \"web_search\",  # ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë¼ìš°íŒ…\n",
    "        \"vectorstore\": \"retrieve\",  # ë²¡í„°ìŠ¤í† ì–´ë¡œ ë¼ìš°íŒ…\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")  # ì›¹ ê²€ìƒ‰ í›„ ë‹µë³€ ìƒì„±\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")  # ë¬¸ì„œ ê²€ìƒ‰ í›„ í‰ê°€\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",  # ì¿¼ë¦¬ ë³€í™˜ í•„ìš”\n",
    "        \"generate\": \"generate\",  # ë‹µë³€ ìƒì„± ê°€ëŠ¥\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")  # ì¿¼ë¦¬ ë³€í™˜ í›„ ë¬¸ì„œ ê²€ìƒ‰\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    hallucination_check,\n",
    "    {\n",
    "        \"hallucination\": \"generate\",  # Hallucination ë°œìƒ ì‹œ ì¬ìƒì„±\n",
    "        \"relevant\": END,  # ë‹µë³€ì˜ ê´€ë ¨ì„± ì—¬ë¶€ í†µê³¼\n",
    "        \"not relevant\": \"transform_query\",  # ë‹µë³€ì˜ ê´€ë ¨ì„± ì—¬ë¶€ í†µê³¼ ì‹¤íŒ¨ ì‹œ ì¿¼ë¦¬ ë³€í™˜\n",
    "    },\n",
    ")\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f4505",
   "metadata": {},
   "source": [
    "ê·¸ë˜í”„ë¥¼ ì‹œê°í™” í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46ce79fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Visualize Graph Error: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2739b",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ ì‚¬ìš©\n",
    "\n",
    "**ê·¸ë˜í”„ ì‚¬ìš©** ë‹¨ê³„ì—ì„œëŠ” **Adaptive RAG**ì˜ ì‹¤í–‰ì„ í†µí•´ ì¿¼ë¦¬ ì²˜ë¦¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ê·¸ë˜í”„ì˜ ê° ë…¸ë“œì™€ ì—£ì§€ë¥¼ ë”°ë¼ ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ê·¸ë˜í”„ ì‹¤í–‰**: ì •ì˜ëœ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¿¼ë¦¬ì˜ íë¦„ì„ ë”°ë¼ê°‘ë‹ˆë‹¤.\n",
    "- **ê²°ê³¼ í™•ì¸**: ê·¸ë˜í”„ ì‹¤í–‰ í›„ ìƒì„±ëœ ê²°ê³¼ë¥¼ ê²€í† í•˜ì—¬ ì¿¼ë¦¬ê°€ ì ì ˆíˆ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "- **ê²°ê³¼ ë¶„ì„**: ìƒì„±ëœ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì¿¼ë¦¬ì˜ ëª©ì ì— ë¶€í•©í•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b020b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== [ROUTE QUESTION] ====\n",
      "==== [ROUTE QUESTION TO VECTORSTORE] ====\n",
      "==== [RETRIEVE] ====\n",
      "==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "==== [DECISION TO GENERATE] ====\n",
      "==== [DECISION: GENERATE] ====\n",
      "==== [GENERATE] ====\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mgenerate\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ì‚¼ì„±ì „ìê°€ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ 'ì‚¼ì„± ê°€ìš°ìŠ¤'ì…ë‹ˆë‹¤.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf (page 12)==== [CHECK HALLUCINATIONS] ====\n",
      "==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\n",
      "==== [GRADE GENERATED ANSWER vs QUESTION] ====\n",
      "==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_graph, random_uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# config ì„¤ì •(ì¬ê·€ ìµœëŒ€ íšŸìˆ˜, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\n",
    "    \"question\": \"ì‚¼ì„±ì „ìê°€ ê°œë°œí•œ ìƒì„±í˜• AI ì˜ ì´ë¦„ì€?\",\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e25d23b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== [ROUTE QUESTION] ====\n",
      "==== [ROUTE QUESTION TO WEB SEARCH] ====\n",
      "==== [WEB SEARCH] ====\n",
      "==== [GENERATE] ====\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mgenerate\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "2024ë…„ ë…¸ë²¨ ë¬¸í•™ìƒ ìˆ˜ìƒìëŠ” í•œêµ­ ì‘ê°€ í•œê°•ì…ë‹ˆë‹¤. \n",
      "\n",
      "**Source**\n",
      "- https://www.yna.co.kr/view/MYH20241010024300704==== [CHECK HALLUCINATIONS] ====\n",
      "==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\n",
      "==== [GRADE GENERATED ANSWER vs QUESTION] ====\n",
      "==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\n",
    "    \"question\": \"2024ë…„ ë…¸ë²¨ ë¬¸í•™ìƒ ìˆ˜ìƒìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\",\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu-rag-j_hBGe1v-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
